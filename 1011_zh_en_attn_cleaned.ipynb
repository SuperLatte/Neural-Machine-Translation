{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from sacrebleu import raw_corpus_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define constants here\n",
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 5\n",
    "MAX_LENGTH = 80\n",
    "words_to_load = 50000\n",
    "emb_size = 300\n",
    "wiki_size = 300\n",
    "CUDA = True\n",
    "\n",
    "datadir = os.getcwd() + '/'\n",
    "datadir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained word embeddings:\n",
    "Reference: https://fasttext.cc/docs/en/pretrained-vectors.html\n",
    "\n",
    "@article{bojanowski2017enriching,\n",
    "  title={Enriching Word Vectors with Subword Information},\n",
    "  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},\n",
    "  journal={Transactions of the Association for Computational Linguistics},\n",
    "  volume={5},\n",
    "  year={2017},\n",
    "  issn={2307-387X},\n",
    "  pages={135--146}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference Lab4&HW2 pretrain loading: English pre trained embedding loading\n",
    "#Due to computation power, only use 50000 words\n",
    "\n",
    "words_to_load = 50000\n",
    "\n",
    "#Wiki has embedding size 300\n",
    "with open(datadir + 'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_en_embeddings = np.zeros(((words_to_load+4), wiki_size))\n",
    "    en_word2id = {}\n",
    "    en_id2words = {}\n",
    "    \n",
    "    en_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    en_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    en_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    en_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    en_word2id['<PAD>'] = PAD_TOKEN\n",
    "    en_word2id['<SOS>'] = SOS_TOKEN\n",
    "    en_word2id['<EOS>'] = EOS_TOKEN\n",
    "    en_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    en_ordered_words= []\n",
    "    en_ordered_words.append('<PAD>')\n",
    "    en_ordered_words.append('<SOS>')\n",
    "    en_ordered_words.append('<EOS>')\n",
    "    en_ordered_words.append('<UNK>')\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load:\n",
    "            break\n",
    "        if i ==0:#Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        #print(len(s))\n",
    "        #Due to 4 default tokens, increment index by 4\n",
    "        loaded_en_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        en_word2id[s[0]] = i+4 #for extra pad and unk eos and unk\n",
    "        en_id2words[i+4] = s[0]\n",
    "        en_ordered_words.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference Lab4&HW2 pretrain loading: Chinese pre trained embedding loading: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "#Over 200000 loaded words, 58 has wrong dimensions\n",
    "#Too slow, swtiched to 50000\n",
    "words_to_load = 50000\n",
    "# datadir = os.getcwd()\n",
    "with open(datadir + 'cc.zh.300.vec') as f:\n",
    "    loaded_zh_embeddings = np.zeros(((words_to_load+4),wiki_size))\n",
    "    zh_word2id = {}\n",
    "    zh_id2words = {}\n",
    "    \n",
    "    zh_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    zh_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    zh_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    zh_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    zh_word2id['<PAD>'] = PAD_TOKEN\n",
    "    zh_word2id['<SOS>'] = SOS_TOKEN\n",
    "    zh_word2id['<EOS>'] = EOS_TOKEN\n",
    "    zh_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    zh_ordered_words= []\n",
    "    zh_ordered_words.append('<PAD>')\n",
    "    zh_ordered_words.append('<SOS>')\n",
    "    zh_ordered_words.append('<EOS>')\n",
    "    zh_ordered_words.append('<UNK>')\n",
    "    wrong_dim = 0;\n",
    "    for i, line in enumerate(f):\n",
    "        #print(line)\n",
    "        if i >= words_to_load:\n",
    "            break;\n",
    "        if i == 0: #Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        if len(s) != 301:\n",
    "            wrong_dim += 1#Skip the wrong dimension one\n",
    "            continue;\n",
    "        loaded_zh_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        zh_word2id[s[0]] = i+4 #for extra pad and unk \n",
    "        zh_id2words[i+4] = s[0]\n",
    "        zh_ordered_words.append(s[0])\n",
    "    print('In total {} has wrong dimension, hence skipped'.format(wrong_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(loaded_zh_embeddings, open(datadir+'zh_embeddings.p', 'wb'))\n",
    "pkl.dump(loaded_en_embeddings, open(datadir+'en_embeddings.p', 'wb'))\n",
    "#pkl.dump(loaded_vi_embeddings, open(datadir+'vi_embeddings.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing stage: \n",
    "1. read language\n",
    "2. data cleaning\n",
    "3. transform to index tensor\n",
    "4. Generate dataloader and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name, emb_word2id, emb_id2word, emb_ordered_words):\n",
    "        self.name = name\n",
    "        self.word2index = emb_word2id\n",
    "        self.word2count = {}\n",
    "        self.index2word = emb_id2word #Dict\n",
    "        self.n_words = 4  # Count SOS, EOS, UNK AND PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count:\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "#Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s, lang):\n",
    "    if lang == \"en\":\n",
    "        s = s.replace(\"apos\", \"\").replace(\"quot\", \"\")\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #This line is commented out since it will not properly deal with Chinese Letters\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "#reference: Lab4+HW2: data preprcoessing\n",
    "def indexesFromSentences(lang1, lang2, pairs):\n",
    "    id_list1 = []\n",
    "    id_list2 = []\n",
    "    for i in range(len(pairs)):\n",
    "        sentence1 = pairs[i][0]\n",
    "        sentence2 = pairs[i][1]\n",
    "        \n",
    "        #Remove strange tokens\n",
    "        sentence1 = sentence1.replace('quot','')\n",
    "        sentence1 = sentence1.replace('apos', '')\n",
    "        sentence2 = sentence2.replace('quot','')\n",
    "        sentence2 = sentence2.replace('apos', '')\n",
    "        #If either sentence is empty, then remove the pair\n",
    "        if sentence1 == '' or sentence2 == '':\n",
    "            continue;\n",
    "        \n",
    "        #Append EOS TOKEN and UNK if not in the vocab\n",
    "        id_sentence1 = [lang1.word2index[word] if word in lang1.word2index else UNK_TOKEN \n",
    "                        for word in sentence1.split()] + [EOS_TOKEN]\n",
    "        id_list1.append(id_sentence1)\n",
    "        id_sentence2 = [lang2.word2index[word] if word in lang2.word2index else UNK_TOKEN \n",
    "                        for word in sentence2.split()] + [EOS_TOKEN]\n",
    "        id_list2.append(id_sentence2)\n",
    "        \n",
    "   \n",
    "        \n",
    "    return id_list1,id_list2\n",
    "\n",
    "# def sentence2id(sentence_list):\n",
    "#     id_list = []\n",
    "#     for sentence in sentence_list:\n",
    "#         sentence_id_list = [word2id[word] if word in word2id else UNK_IDX for word in sentence]\n",
    "#         id_list.append(sentence_id_list)\n",
    "#     return id_list\n",
    "\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_TOKEN)\n",
    "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "#     return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "# def filterPair(p):\n",
    "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "#         len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "#         p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "# def filterPairs(pairs):\n",
    "#     return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Modified readLang, only used to count number of words\n",
    "def readLangs(lang1, lang2, category, reverse = False):#category = ['train', 'dev','test]\n",
    "    print('Reading lines:')\n",
    "    lines1 = open(category +'.tok.'+ lang1.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data1 = [normalizeString(l, lang1.name) for l in lines1]\n",
    "    #data1 = list(filter(None, data1)) # fastest\n",
    "\n",
    "    lines2 = open(category + '.tok.' + lang2.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data2 = [normalizeString(l, lang2.name) for l in lines2]\n",
    "    #Given that data2 is english hence we further normalize\n",
    "    data2 = [re.sub(r\"[^a-zA-Z.!?]+\", r\" \", data) for data in data2]\n",
    "    #data2 = list(filter(None, data2)) # fastest\n",
    "\n",
    "    return data1, data2\n",
    "\n",
    "#Data Preparation for CHN to ENG\n",
    "def prepareData(lang1, lang2, category, reverse = False):\n",
    "    data1, data2 = readLangs(lang1, lang2, category, reverse)#Read data returns list of sentences\n",
    "    pairs = [[data1[i], data2[i]] for i in range(len(data1))]\n",
    "    print('Read %s sentence pairs' % len(pairs))\n",
    "    #Count the words\n",
    "    print('Counting words')\n",
    "    for i in range(len(pairs)):\n",
    "        lang1.addSentence(data1[i])\n",
    "        lang2.addSentence(data2[i])\n",
    "\n",
    "    print('Counted Words')\n",
    "    print(lang1.name, lang1.n_words)\n",
    "    print(lang2.name, lang2.n_words)\n",
    "\n",
    "    return pairs, data1, data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create language object\n",
    "input_zh = Lang('zh', zh_word2id, zh_id2words, zh_ordered_words)\n",
    "output_zh_en = Lang('en', en_word2id, en_id2words, en_ordered_words)\n",
    "# input_vi = Lang('vi', vi_word2id, vi_id2words, vi_ordered_words)\n",
    "# output_vi_en = Lang('en', en_word2id, en_id2words, en_ordered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the string pairs and the string lists\n",
    "train_zh_pairs, zh_train, zh_en_train = prepareData(input_zh, output_zh_en, 'train')\n",
    "val_zh_pairs, zh_val, zh_en_val = prepareData(input_zh, output_zh_en, 'dev')\n",
    "test_zh_pairs, zh_test, zh_en_test = prepareData(input_zh, output_zh_en, 'test')\n",
    "\n",
    "# train_vi_pairs, vi_train, vi_en_train = prepareData(input_vi, output_vi_en, 'train')\n",
    "# val_vi_pairs, vi_val, vi_en_val = prepareData(input_vi, output_vi_en, 'dev')\n",
    "# test_vi_pairs, vi_test, vi_en_test = prepareData(input_vi, output_vi_en, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.choice(train_zh_pairs)\n",
    "i = random.randint(0,len(train_zh_pairs))\n",
    "print('random number is {}, and the pair is {}'.format(i, train_zh_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transfer to index tensor and generate pairs\n",
    "zh_idx_train, zh_en_idx_train = indexesFromSentences(input_zh, output_zh_en, train_zh_pairs)\n",
    "zh_idx_val, zh_en_idx_val = indexesFromSentences(input_zh, output_zh_en, val_zh_pairs)\n",
    "zh_idx_test, zh_en_idx_test = indexesFromSentences(input_zh, output_zh_en, test_zh_pairs)\n",
    "\n",
    "zh_train_pairs = [[zh_idx_train[i], zh_en_idx_train[i]] for i in range(len(zh_idx_train))]\n",
    "zh_val_pairs = [[zh_idx_val[i], zh_en_idx_val[i]] for i in range(len(zh_idx_val))]\n",
    "zh_test_pairs= [[zh_idx_test[i], zh_en_idx_test[i]] for i in range(len(zh_idx_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(zh_train_pairs, open('zh_train_pairs.p', 'wb'))\n",
    "pkl.dump(zh_val_pairs, open('zh_val_pairs.p', 'wb'))\n",
    "pkl.dump(zh_test_pairs, open('zh_test_pairs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate the max length of the chinese sentence, and also the second largest\n",
    "max_train_len = 0\n",
    "second_len = 0\n",
    "for pair in zh_train_pairs:\n",
    "    if max_train_len < len(pair[0]):\n",
    "        second_len = max_train_len\n",
    "        max_train_len = len(pair[0])\n",
    "\n",
    "print(max_train_len, second_len)# results in 531 and 502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For training data, we have max-len as 80: train: 132789/133316, val: 1267/1268, test: 1552/1553\n",
    "zh_train_pairs_cleaned= []\n",
    "zh_val_pairs_cleaned = []\n",
    "zh_test_pairs_cleaned = []\n",
    "MAX_LENGTH = 80\n",
    "for zh_list in zh_train_pairs:\n",
    "    if len(zh_list[0])<=MAX_LENGTH and len(zh_list[1]) <= MAX_LENGTH:\n",
    "        zh_train_pairs_cleaned.append(zh_list)\n",
    "        \n",
    "for zh_list in zh_val_pairs:\n",
    "    if len(zh_list[0])<=MAX_LENGTH and len(zh_list[1]) <= MAX_LENGTH:\n",
    "        zh_val_pairs_cleaned.append(zh_list)\n",
    "\n",
    "for zh_list in zh_test_pairs:\n",
    "    if len(zh_list[0])<=MAX_LENGTH and len(zh_list[1]) <= MAX_LENGTH:\n",
    "        zh_test_pairs_cleaned.append(zh_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(zh_train_pairs_cleaned, open('zh_train_pairs_cleaned.p', 'wb'))\n",
    "pkl.dump(zh_val_pairs_cleaned, open('zh_val_pairs_cleaned.p', 'wb'))\n",
    "pkl.dump(zh_test_pairs_cleaned, open('zh_test_pairs_cleaned.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80\n",
    "\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, pairs):#Needs the index pairs\n",
    "        self.pairs = pairs\n",
    "#         self.input_lang = input_lang\n",
    "#         self.output_lang = output_lang\n",
    "        self.input_seqs = [pairs[i][0] for i in range(len(self.pairs))]\n",
    "        self.output_seqs = [pairs[i][1] for i in range(len(self.pairs))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)#Returning number of pairs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_seq = self.input_seqs[index]\n",
    "        output_seq = self.output_seqs[index]\n",
    "        return [input_seq, len(input_seq), output_seq, len(output_seq)]\n",
    "    \n",
    "def vocab_collate_func(batch):\n",
    "    #Reference: lab8_3_mri vocab_collate func\n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq) for seq in seqs]\n",
    "#         padded_seqs = torch.zeros(len(seqs), max(lens)).long()\n",
    "        padded_seqs = torch.zeros(len(seqs), MAX_LENGTH).long()\n",
    "        for i, seq in enumerate(seqs):\n",
    "            end = lens[i]\n",
    "            padded_seqs[i, :end] = torch.LongTensor(seq[:end])\n",
    "        return padded_seqs, lens\n",
    "    \n",
    "    batch_input_seqs = [datum[0] for datum in batch]\n",
    "    batch_output_seqs = [datum[2] for datum in batch]\n",
    "    #batch_input_length = [datum[1] for datum in batch]\n",
    "    #batch_output_length = [datum[3] for datum in batch]\n",
    "\n",
    "    sorted_pairs = sorted(zip(batch_input_seqs, batch_output_seqs), key=lambda x: len(x[0]), reverse = True)\n",
    "    in_seq_sorted, out_seq_sorted = zip(*sorted_pairs)\n",
    "    \n",
    "    padded_input,input_lens = _pad_sequences(in_seq_sorted)\n",
    "    padded_output,output_lens = _pad_sequences(out_seq_sorted)\n",
    "    \n",
    "    input_list = torch.from_numpy(np.array(padded_input))\n",
    "    input_length = torch.LongTensor(input_lens)\n",
    "    output_list = torch.from_numpy(np.array(padded_output))\n",
    "    output_length = torch.LongTensor(output_lens)\n",
    "    \n",
    "    if CUDA:\n",
    "        input_list = input_list.cuda()\n",
    "        output_list = output_list.cuda()\n",
    "        input_length = input_length.cuda()\n",
    "        output_length = output_length.cuda()\n",
    "            \n",
    "    return [input_list, input_length, output_list, output_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "'''\n",
    "NMTDataset needs index pairs, need to call indexesFromPairs functions beforehand\n",
    "The dataLoader is sorted according to length of the input_length, and padded to\n",
    "max length of input and output list repectively\n",
    "output_list is not sorted, hence need to sort (maybe) in the rnn sequence.\n",
    "'''\n",
    "\n",
    "train_zh_dataset = NMTDataset(zh_train_pairs_cleaned)\n",
    "val_zh_dataset = NMTDataset(zh_val_pairs_cleaned)\n",
    "test_zh_dataset = NMTDataset(zh_test_pairs_cleaned)\n",
    "\n",
    "\n",
    "train_zh_loader = torch.utils.data.DataLoader(dataset = train_zh_dataset, \n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = True)\n",
    "\n",
    "#Will use batch size 1 for validation and test since the sentence will be translated one by one\n",
    "val_zh_loader = torch.utils.data.DataLoader(dataset = val_zh_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "\n",
    "test_zh_loader = torch.utils.data.DataLoader(dataset = test_zh_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "\n",
    "#Input_batch in size Batch x maxLen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate one batch for testing purpose\n",
    "for i, (input_list, input_length, output_list, output_length) in enumerate(train_zh_loader):\n",
    "    if i== 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of data preprocessing stage\n",
    "-----\n",
    "### Batch Encoder with pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#More constant definition\n",
    "# MAX_SENTENCE_LENGTH = 10\n",
    "hidden_size = 256\n",
    "TEST_BATCH_SIZE = 3\n",
    "CLIP = 50\n",
    "TEACHER_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_zh_embeddings = pkl.load(open(datadir+'zh_embeddings.p', 'rb'))\n",
    "loaded_en_embeddings = pkl.load(open(datadir+'en_embeddings.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_zh_embeddings = torch.from_numpy(loaded_zh_embeddings).float()\n",
    "#loaded_vi_embeddings = torch.from_numpy(loaded_vi_embeddings).float()\n",
    "loaded_en_embeddings = torch.from_numpy(loaded_en_embeddings).float()\n",
    "\n",
    "if CUDA:\n",
    "    loaded_zh_embeddings = loaded_zh_embeddings.cuda()\n",
    "    #loaded_vi_embeddings = loaded_vi_embeddings.cuda()\n",
    "    loaded_en_embeddings = loaded_en_embeddings.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference Lab8 1-nmt\n",
    "class PreBatchEncoderRNN(nn.Module):\n",
    "    def __init__(self, emb, emb_size, hidden_size , n_layers = 1, dropout_p = 0.1):\n",
    "        super(PreBatchEncoderRNN, self).__init__()\n",
    "        #self.input_size = input_size\n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.embedding = nn.Embedding.from_pretrained(self.emb, True)\n",
    "        self.gru = nn.GRU(self.emb_size, hidden_size, bidirectional = True, batch_first = True)\n",
    "\n",
    "    def forward(self, input_list, input_length, hidden):\n",
    "        self.batch_size = input_list.size(0)\n",
    "        embedded = self.embedding(input_list)#Batch x seq x emb_size=300\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        #Input length sorted by loader already\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_length,  batch_first = True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        #Padded back to maximum length\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first = True, total_length = MAX_LENGTH)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        \n",
    "        #outputs B x L x H\n",
    "        #hidden size (2*n_layers) x B x H\n",
    "        return outputs, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(2*self.n_layers, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encoder testout\n",
    "encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "hidden = encoder.initHidden(BATCH_SIZE)\n",
    "encoder_outputs, encoder_hidden = encoder(input_list, input_length, hidden)\n",
    "encoder_outputs.size(), encoder_hidden.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "#Reference: Lab8 nmt-1\n",
    "class PreBatchAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, emb, emb_size, hidden_size, output_size, n_layers = 1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(PreBatchAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        #self.attn = nn.Linear(hidden_size*2, hidden_size)\n",
    "        #self.attn2 = nn.Linear(hidden_size, hidden_size)\n",
    "        #self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        self.embedding = nn.Embedding.from_pretrained(self.emb, True)\n",
    "        self.attn = nn.Linear(emb_size + hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(emb_size + hidden_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, batch_first = False)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, decoder_input, hidden, encoder_outputs):\n",
    "        self.batch_size = encoder_outputs.size(0)\n",
    "        embedded = self.embedding(decoder_input).view(1, self.batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        concat_input = torch.cat((embedded, hidden), 2)\n",
    "        attn_weights = F.softmax(self.attn(concat_input), dim=2)\n",
    "        attn_energies = torch.bmm(attn_weights.squeeze(0).unsqueeze(1), encoder_outputs).squeeze(1)#Batch x H\n",
    "\n",
    "        output = torch.cat((embedded.squeeze(0), attn_energies), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        rnn_output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(rnn_output.squeeze(0)),dim=1)\n",
    "        #Size: output b x V, hidden 1 x b x h, attn 1 x b x max_length\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "#     def initHidden(self, batch_size):\n",
    "#         return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test for decoder\n",
    "decoder_input = torch.tensor([SOS_TOKEN] * BATCH_SIZE).to(device)\n",
    "last_hidden = encoder_hidden[:1]#We assume that the decoder has layer 1\n",
    "test_decoder = PreBatchAttnDecoderRNN(loaded_zh_embeddings, emb_size,hidden_size, len(zh_ordered_words)).to(device)\n",
    "decoder_output, decoder_hidden, attn_weights = test_decoder(decoder_input, last_hidden, encoder_outputs)\n",
    "decoder_output.size(), decoder_hidden.size(), attn_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Full run testing\n",
    "hidden_size = 256\n",
    "test_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "test_decoder = PreBatchAttnDecoderRNN(loaded_en_embeddings, emb_size,hidden_size, len(en_ordered_words)).to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i, (input_list,input_length,output_list, output_length) in enumerate(train_zh_loader):\n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "            \n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_outputs, encoder_hidden = test_encoder(input_list, input_length, encoder_hidden)\n",
    "    \n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size), device=device)\n",
    "    decoder_hidden = encoder_hidden[:test_decoder.n_layers]#Only up to the layer\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    #Will feed one token * batch_size at a time into the decoder\n",
    "    for di in range(max_output_length):\n",
    "\n",
    "        decoder_output, decoder_hidden, decoder_attention = test_decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        loss += criterion(decoder_output, output_list[:,di])\n",
    "        decoder_input = output_list[:,di].unsqueeze(0) \n",
    "    loss.backward()\n",
    "    if i== 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of encoder decoder session\n",
    "----\n",
    "### Training and evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Referenced from Lab 8 1nmt and modified \n",
    "teacher_forcing_ratio = 0.5\n",
    "def attn_batch_train(input_list, input_length, output_list,output_length, \n",
    "                batch_encoder, batch_decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    '''\n",
    "    param: @attention is a Boolean variable indicating whether using attention\n",
    "    '''\n",
    "    batch_encoder.train()\n",
    "    batch_decoder.train()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = batch_encoder.initHidden(batch_size)\n",
    "    encoder_outputs, encoder_hidden = batch_encoder(input_list, input_length, encoder_hidden)\n",
    "\n",
    "    #Initialize for decoding process\n",
    "    #curr_batch = input_list.size(0)#Take the current batch size\n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size), device=device)\n",
    "    decoder_hidden = encoder_hidden[:batch_decoder.n_layers]#Bidirectional summoned\n",
    "    #     decoder_outputs = torch.zeros(MAX_LEN, curr_batch, batch_decoder.output_size)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = batch_decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = output_list[:,di].unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "\n",
    "    else:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = batch_decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "            \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()/MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test for training fucntion\n",
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "\n",
    "encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "decoder = PreBatchAttnDecoderRNN(loaded_en_embeddings, emb_size,hidden_size, len(en_ordered_words)).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "loss = attn_batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overfitting mini batches\n",
    "pre_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size, BATCH_SIZE).to(device)\n",
    "attn_decoder = PreAttnDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), BATCH_SIZE).to(device)\n",
    "\n",
    "learning_rate = 0.01\n",
    "encoder_optimizer = optim.Adam(pre_encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(attn_decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss = []\n",
    "for i in range(2000):\n",
    "    loss = attn_batch_train(input_list, input_length, output_list, output_length, \n",
    "                       pre_encoder, attn_decoder, encoder_optimizer, decoder_optimizer, \n",
    "                       criterion)\n",
    "    train_loss.append(loss)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,10))\n",
    "ax.plot(train_loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference lab8 1-nmt\n",
    "def greedy_attn_evaluate(val_loader, encoder, decoder, en_id2words):\n",
    "    #Will generate sentences 1 by 1. \n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param val_loader: use dataloader to generate a batch of data\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param en_id2words: the translation dictionary to translate index to words\n",
    "    @output decoded_words_all: a list of words in target language\n",
    "    @output decoder_attentions_all: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    decoded_words_all = []\n",
    "    decoder_attentions_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for i, (input_list, input_length, output_list, output_length) in enumerate(val_loader):\n",
    "            if i %100 == 0:\n",
    "                print(\"%d/%d\"%(i,len(val_loader)))\n",
    "                \n",
    "            batch_size, max_input_length = input_list.size()\n",
    "            max_output_length = output_list.size(1)\n",
    "            \n",
    "            #if i == 5:\n",
    "            #    break\n",
    "            #batch_size, max_len = output_list.size()\n",
    "#             print(input_list.size())\n",
    "            \n",
    "            #Start the encoding process\n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_outputs, encoder_hidden = encoder(input_list, input_length, encoder_hidden)\n",
    "            \n",
    "            \n",
    "            #Start the decoding process\n",
    "            decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size), device=device)\n",
    "            decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "            \n",
    "            decoded_words = []\n",
    "            decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "                top_score, topi = decoder_output.data.topk(1)\n",
    "                decoder_attentions[di, :decoder_attention.size(-1)] = decoder_attention\n",
    "                decoded_words.append(en_id2words[topi.item()])\n",
    "                if topi.item() == EOS_TOKEN:\n",
    "                    break\n",
    "                else:\n",
    "                    decoder_input = topi.squeeze().detach()\n",
    "                    \n",
    "            decoded_words_all.append(decoded_words)\n",
    "            decoder_attentions_all.append(decoder_attentions[:di+1])\n",
    "\n",
    "        return decoded_words_all, decoder_attentions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_process(decoded_words_all):\n",
    "    cleaned_decoded_words_all = []\n",
    "    \n",
    "    for sentence in decoded_words_all:\n",
    "        cleaned_sentence = []\n",
    "        for word in sentence:\n",
    "            if word == '<PAD>':\n",
    "                continue\n",
    "            else:\n",
    "                cleaned_sentence.append(word)\n",
    "        if cleaned_sentence[-1] != '<EOS>':\n",
    "            cleaned_sentence.append(' <EOS>')\n",
    "            \n",
    "        cleaned_decoded_words_all.append(cleaned_sentence)\n",
    "        \n",
    "    return cleaned_decoded_words_all\n",
    "\n",
    "#Translate the test and val lists back to english\n",
    "def en_translate(index_list, en_id2words):\n",
    "    translated_sentence_list = []\n",
    "    for sentence in index_list:\n",
    "        translated_sentence = []\n",
    "        for index in sentence:\n",
    "            translated_sentence.append(en_id2words[index])\n",
    "        #translated_sentence.append('<EOS>')\n",
    "        translated_sentence_list.append(translated_sentence)\n",
    "    return translated_sentence_list\n",
    "\n",
    "def zh_translate(index_list, zh_id2words):\n",
    "    translated_sentence_list = []\n",
    "    for sentence in index_list:\n",
    "        translated_sentence = []\n",
    "        for index in sentence:\n",
    "            translated_sentence.append(zh_id2words[index])\n",
    "        #translated_sentence.append('<EOS>')\n",
    "        translated_sentence_list.append(translated_sentence)\n",
    "    return translated_sentence_list\n",
    "\n",
    "def concatenate_tokens(token_lists):\n",
    "    sentence_list = []\n",
    "    for token_list in token_lists:\n",
    "        sentence = ''\n",
    "        for token in token_list:\n",
    "            sentence = sentence+' '+token\n",
    "        sentece_list.append(sentence)\n",
    "    return sentence_list\n",
    "        \n",
    "def bleu_score(pred_list, target_list):\n",
    "    pred_sentence_list = concatenate_tokens(pred_list)\n",
    "    target_sentence_list = concatenate_tokens(target_list)\n",
    "    print('bleu score for test dataset:', corpus_bleu(pred_sentence_list, [target_sentence_list]).score)\n",
    "    print('bleu score for test dataset [raw]:', raw_corpus_bleu(pred_sentence_list, [target_sentence_list]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Translate the index validation data back to english\n",
    "zh_en_val_list = [pair[1] for pair in zh_val_pairs_cleaned]\n",
    "translated_sentence_list = en_translate(zh_en_val_list, en_id2words)\n",
    "translated_sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(translated_sentence_list, open('translated_sentence_list.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zh_en_test_list = [pair[0] for pair in zh_val_pairs_cleaned]\n",
    "zh_translated_sentence_list = zh_translate(zh_en_val_list, zh_id2words)\n",
    "zh_translated_sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(zh_translated_sentence_list, open('zh_translated_sentence_list_val.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference LAB8 1-nmt\n",
    "model_path = datadir\n",
    "def AttnTrainIters(train_loader, val_loader, encoder, decoder, n_iters, val_translated_list,\n",
    "                   print_every=100, plot_every=100, eval_every=500, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    total_sample = 0\n",
    "    total_loss_list = []\n",
    "    for iter in range(n_iters):\n",
    "        losses = []\n",
    "        plot_loss_total = 0\n",
    "        print_loss_total = 0\n",
    "        for i, (input_list,input_length,output_list, output_length) in enumerate(train_loader):\n",
    "            loss = attn_batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            \n",
    "            total_loss_list.append(loss)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "#             if i > 0 and i % eval_every == 0:\n",
    "#                 decoded_val, decoder_attentions = greedy_attn_evaluate(val_loader, encoder, decoder, en_id2words)\n",
    "#                 decoded_clean = post_process(decoded_val)\n",
    "#                 print('bleu score is {}'.format(raw_corpus_bleu(decoded_val, val_translated_list).score))\n",
    "\n",
    "            if i > 0 and i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, total_sample / (n_iters*len(train_loader)) ),\n",
    "                                             total_sample, total_sample / (n_iters*len(train_loader)) * 100, print_loss_avg))\n",
    "\n",
    "            if i > 0 and i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "            total_sample += 1\n",
    "            \n",
    "        torch.save(encoder.state_dict(), model_path + \"encoder_rnn_attn2_\"+str(start)+\".pth\")\n",
    "        torch.save(decoder.state_dict(), model_path + \"decoder_rnn_attn2_\"+str(start)+\".pth\")\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return total_loss_list, plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_size = 300\n",
    "\n",
    "encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "attn_decoder = PreBatchAttnDecoderRNN(loaded_en_embeddings, emb_size,hidden_size, len(en_ordered_words)).to(device)\n",
    "\n",
    "total_loss_list_en, plot_losses_en = AttnTrainIters(train_zh_loader, val_zh_loader, encoder, attn_decoder, 3,\n",
    "               None, print_every=100, learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(total_loss_list_en, open('total_loss_list_en.p', 'wb'))\n",
    "pkl.dump(plot_losses_en, open('plot_losses_en.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "ax.yaxis.set_major_locator(loc)\n",
    "plt.plot(plot_loss_append)\n",
    "\n",
    "plt.title('Training loss curve on ZH-EN for decoder with attnetion')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('zh_attn_training_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding and evaluating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_val, decoder_attentions = greedy_attn_evaluate(val_zh_loader, encoder, attn_decoder, en_id2words)\n",
    "decoded_clean = post_process(decoded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(decoded_test_clean, open('attn_decoded_clean5.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SearchNode(object):\n",
    "    def __init__(self, word_idx, hidden, prev, curr_score, length):\n",
    "        self.hidden = hidden\n",
    "        self.word_idx = word_idx\n",
    "        self.prev = prev\n",
    "        \n",
    "        if self.prev == None:\n",
    "            self.score = curr_score\n",
    "        else:\n",
    "            self.score = self.prev.score + curr_score\n",
    "        self.length = length\n",
    "\n",
    "#Translate the sentences.\n",
    "def translate_end_nodes(end_nodes):\n",
    "    sentences = []\n",
    "    #end_nodes = sorted(end_nodes, key = operator.itemgetter(0),reverse = True)\n",
    "    for _, end_node in end_nodes:\n",
    "        sentence = []\n",
    "        while end_node.prev != None:\n",
    "            sentence.append(en_id2words[end_node.word_idx.item()])\n",
    "            end_node = end_node.prev\n",
    "        sentence = sentence[::-1]#Reverse the sentence to get the sentence\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference: https://github.com/budzianowski/PyTorch-Beam-Search-Decoding/blob/master/decode_beam.py\n",
    "def beam_evaluate(val_loader, encoder, decoder, beam_width, k):\n",
    "    '''\n",
    "    beam_width: number of best nodes kept at each iterations\n",
    "    k: number of sentences we want to keep\n",
    "    Returns the translated batch\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    decoded_batch = []\n",
    "    #decoder_attentions = torch.zeros(max_length, batch_size, max_input_length)#in length, each position has attention\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for i, (input_list, input_length, output_list, output_length) in enumerate(val_loader):\n",
    "            if i %100 == 0:\n",
    "                print(\"%d/%d\"%(i,len(val_loader)))\n",
    "                    \n",
    "            #    break\n",
    "            #batch_size, max_len = output_list.size()\n",
    "#             print(input_list.size())\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden(1)\n",
    "            encoder_outputs, encoder_hidden = encoder(input_list, input_length, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor(np.array([[SOS_TOKEN]]), device=device) #SOS 1 sentence a time\n",
    "            decoder_hidden = encoder_hidden[:decoder.n_layers] # decoder starts from the last encoding sentence\n",
    "            # output of this function\n",
    "            \n",
    "            decoded_words = []\n",
    "            #decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
    "            \n",
    "            start_node = SearchNode(decoder_input, decoder_hidden, prev = None, curr_score = 0, length = 1)\n",
    "            nodes = PriorityQueue()\n",
    "            nodes.put(( -(start_node.score), start_node))\n",
    "            end_nodes = []\n",
    "            \n",
    "\n",
    "            while(len(end_nodes) < k):\n",
    "                curr_score, curr_node = nodes.get()\n",
    "                if (curr_node.word_idx == EOS_TOKEN) and (curr_node.prev != None):\n",
    "                    end_nodes.append((-(curr_node.score),curr_node))\n",
    "                    if len(end_nodes) >=k:\n",
    "                        break;\n",
    "                    else: \n",
    "                        continue;\n",
    "\n",
    "                if nodes.qsize() >= MAX_LENGTH:#if too long will force to stop\n",
    "                    #Create an EOS dummy node to trace back the entire sentence\n",
    "                    EOS_node = SearchNode(torch.tensor([[EOS_TOKEN]], device = device), curr_node.hidden, \n",
    "                                          curr_node, curr_node.score, (curr_node.length)+1)\n",
    "                    end_nodes.append((-(EOS_node.score), EOS_node))\n",
    "                    if len(end_nodes) >= k:\n",
    "                        break;\n",
    "                    else:\n",
    "                        continue;\n",
    "\n",
    "                decoder_input = curr_node.word_idx\n",
    "                decoder_hidden = curr_node.hidden\n",
    "\n",
    "                # for each time step, the decoder network takes two inputs: previous outputs \n",
    "                #and the previous hidden states\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "\n",
    "                scores, indexes = torch.topk(decoder_output, beam_width)\n",
    "                candidate_nodes = []\n",
    "                for i in range(beam_width):\n",
    "                    candidate_idx = indexes[0][i].view(1, -1)\n",
    "                    candidate_score = scores[0][i].item()\n",
    "\n",
    "                    candidate_node = SearchNode(candidate_idx, decoder_hidden, \n",
    "                                                   curr_node, candidate_score, curr_node.length + 1)\n",
    "                    candidate_nodes.append((-(candidate_node.score), candidate_node))\n",
    "\n",
    "                for j in range(beam_width):\n",
    "                    to_push_score, to_push_node = candidate_nodes[j]\n",
    "                    #print(to_push_score)\n",
    "                    nodes.put((-(to_push_score), to_push_node))\n",
    "                #End of the while loop\n",
    "\n",
    "            sentences = translate_end_nodes(end_nodes)\n",
    "            decoded_batch.append(sentences)\n",
    "            #End of the batch loop\n",
    "        \n",
    "    return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_val = beam_evaluate(val_zh_loader, encoder, attn_decoder, 5,1)\n",
    "decoded_clean = post_process(decoded_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
