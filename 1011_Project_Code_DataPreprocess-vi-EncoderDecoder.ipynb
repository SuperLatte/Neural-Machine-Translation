{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "from sacrebleu import raw_corpus_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants here\n",
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 3\n",
    "words_to_load = 80000\n",
    "emb_size = 300\n",
    "wiki_size = 300\n",
    "CUDA = True\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.getcwd()\n",
    "datadir\n",
    "ftdir = '/scratch/yz4499/fasttext/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained word embeddings:\n",
    "Reference: https://fasttext.cc/docs/en/pretrained-vectors.html\n",
    "\n",
    "@article{bojanowski2017enriching,\n",
    "  title={Enriching Word Vectors with Subword Information},\n",
    "  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},\n",
    "  journal={Transactions of the Association for Computational Linguistics},\n",
    "  volume={5},\n",
    "  year={2017},\n",
    "  issn={2307-387X},\n",
    "  pages={135--146}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference Lab4 HW2\n",
    "# datadir = os.getcwd()\n",
    "words_to_load = 50000\n",
    "# with open(datadir + '/data/wiki-news-300d-1M.vec') as f:\n",
    "with open(ftdir + 'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_en_embeddings = np.zeros(((words_to_load+4), wiki_size))\n",
    "    en_word2id = {}\n",
    "    en_id2words = {}\n",
    "    \n",
    "    en_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    en_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    en_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    en_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    en_word2id['<PAD>'] = PAD_TOKEN\n",
    "    en_word2id['<SOS>'] = SOS_TOKEN\n",
    "    en_word2id['<EOS>'] = EOS_TOKEN\n",
    "    en_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    en_ordered_words= []\n",
    "    en_ordered_words.append('<PAD>')\n",
    "    en_ordered_words.append('<SOS>')\n",
    "    en_ordered_words.append('<EOS>')\n",
    "    en_ordered_words.append('<UNK>')\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load:\n",
    "            break\n",
    "        if i ==0:#Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        #print(len(s))\n",
    "        loaded_en_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        en_word2id[s[0]] = i+4 #for extra pad and unk eos and unk\n",
    "        en_id2words[i+4] = s[0]\n",
    "        en_ordered_words.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 0 has wrong dimension, hence skipped\n"
     ]
    }
   ],
   "source": [
    "#Reference Lab4 HW2\n",
    "#Over 200000 loaded words, 58 has wrong dimensions\n",
    "words_to_load = 50000\n",
    "# datadir = os.getcwd()\n",
    "with open(ftdir + 'cc.vi.300.vec') as f:\n",
    "    loaded_vi_embeddings = np.zeros(((words_to_load+4),wiki_size))\n",
    "    vi_word2id = {}\n",
    "    vi_id2words = {}\n",
    "    \n",
    "    vi_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    vi_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    vi_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    vi_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    vi_word2id['<PAD>'] = PAD_TOKEN\n",
    "    vi_word2id['<SOS>'] = SOS_TOKEN\n",
    "    vi_word2id['<EOS>'] = EOS_TOKEN\n",
    "    vi_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    vi_ordered_words= []\n",
    "    vi_ordered_words.append('<PAD>')\n",
    "    vi_ordered_words.append('<SOS>')\n",
    "    vi_ordered_words.append('<EOS>')\n",
    "    vi_ordered_words.append('<UNK>')\n",
    "    wrong_dim = 0;\n",
    "    for i, line in enumerate(f):\n",
    "        #print(line)\n",
    "        if i >= words_to_load:\n",
    "            break;\n",
    "        if i == 0: #Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        if len(s) != 301:\n",
    "            wrong_dim += 1#Skip the wrong dimension one\n",
    "            continue;\n",
    "        loaded_vi_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        vi_word2id[s[0]] = i+4 #for extra pad and unk \n",
    "        vi_id2words[i+4] = s[0]\n",
    "        vi_ordered_words.append(s[0])\n",
    "    print('In total {} has wrong dimension, hence skipped'.format(wrong_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(loaded_zh_embeddings, open(ftdir+'zh_embeddings.p', 'wb'))\n",
    "# pkl.dump(loaded_en_embeddings, open(ftdir+'en_embeddings.p', 'wb'))\n",
    "# pkl.dump(loaded_vi_embeddings, open(ftdir+'vi_embeddings.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name, emb_word2id, emb_id2word, emb_ordered_words):\n",
    "        self.name = name\n",
    "        self.word2index = emb_word2id\n",
    "        self.word2count = {}\n",
    "        self.index2word = emb_id2word #Dict\n",
    "        self.n_words = 4  # Count SOS and EOS +(batch: pad and unk)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count:\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "#Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s, lang):\n",
    "    if lang == \"en\":\n",
    "        s = s.replace(\"&apos;\", \"\").replace(\"&quot;\", \"\")\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #This line is commented out since it will not properly deal with Chinese Letters\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "#reference: LAB4 hw2\n",
    "def indexesFromSentences(lang1, lang2, pairs):\n",
    "    id_list1 = []\n",
    "    id_list2 = []\n",
    "    for i in range(len(pairs)):\n",
    "        sentence1 = pairs[i][0]\n",
    "        sentence2 = pairs[i][1]\n",
    "        \n",
    "        sentence1 = sentence1.replace('quot','')\n",
    "        sentence1 = sentence1.replace('apos', '')\n",
    "        sentence2 = sentence2.replace('quot','')\n",
    "        sentence2 = sentence2.replace('apos', '')\n",
    "        #If either sentence is empty, then remove the pair\n",
    "        if sentence1 == '' or sentence2 == '':\n",
    "            continue;\n",
    "        \n",
    "        id_sentence1 = [lang1.word2index[word] if word in lang1.word2index else UNK_TOKEN \n",
    "                        for word in sentence1.split()] + [EOS_TOKEN]\n",
    "        id_list1.append(id_sentence1)\n",
    "        id_sentence2 = [lang2.word2index[word] if word in lang2.word2index else UNK_TOKEN \n",
    "                        for word in sentence2.split()] + [EOS_TOKEN]\n",
    "        id_list2.append(id_sentence2)\n",
    "        \n",
    "   \n",
    "        \n",
    "    return id_list1,id_list2\n",
    "\n",
    "# def sentence2id(sentence_list):\n",
    "#     id_list = []\n",
    "#     for sentence in sentence_list:\n",
    "#         sentence_id_list = [word2id[word] if word in word2id else UNK_IDX for word in sentence]\n",
    "#         id_list.append(sentence_id_list)\n",
    "#     return id_list\n",
    "\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_TOKEN)\n",
    "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "#     return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "# def filterPair(p):\n",
    "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "#         len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "#         p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "# def filterPairs(pairs):\n",
    "#     return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, category, reverse = False):#category = ['train', 'dev','test]\n",
    "    print('Reading lines:')\n",
    "    lines1 = open('data/iwslt-' + lang1.name +'-en/' + category +'.tok.'+ lang1.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data1 = [normalizeString(l, lang1.name) for l in lines1]\n",
    "    #data1 = list(filter(None, data1)) # fastest\n",
    "\n",
    "    lines2 = open('data/iwslt-' + lang1.name +'-en/' + category + '.tok.' + lang2.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data2 = [normalizeString(l, lang2.name) for l in lines2]\n",
    "    #Given that data2 is english hence we further normalize\n",
    "    data2 = [re.sub(r\"[^a-zA-Z.!?]+\", r\" \", data) for data in data2]\n",
    "    #data2 = list(filter(None, data2)) # fastest\n",
    "\n",
    "    return data1, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation for CHN to ENG\n",
    "def prepareData(lang1, lang2, category, reverse = False):\n",
    "    data1, data2 = readLangs(lang1, lang2, category, reverse)#Read data returns list of sentences\n",
    "    pairs = [[data1[i], data2[i]] for i in range(len(data1))]\n",
    "    print('Read %s sentence pairs' % len(pairs))\n",
    "    #Count the words\n",
    "    print('Counting words')\n",
    "    for i in range(len(pairs)):\n",
    "        lang1.addSentence(data1[i])\n",
    "        lang2.addSentence(data2[i])\n",
    "\n",
    "    print('Counted Words')\n",
    "    print(lang1.name, lang1.n_words)\n",
    "    print(lang2.name, lang2.n_words)\n",
    "\n",
    "    return pairs, data1, data2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create language object\n",
    "# input_zh = Lang('zh', zh_word2id, zh_id2words, zh_ordered_words)\n",
    "# output_zh_en = Lang('en', en_word2id, en_id2words, en_ordered_words)\n",
    "input_vi = Lang('vi', vi_word2id, vi_id2words, vi_ordered_words)\n",
    "output_vi_en = Lang('en', en_word2id, en_id2words, en_ordered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines:\n",
      "Read 133317 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "vi 30768\n",
      "en 41271\n",
      "Reading lines:\n",
      "Read 1268 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "vi 30916\n",
      "en 41434\n",
      "Reading lines:\n",
      "Read 1553 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "vi 31057\n",
      "en 41598\n"
     ]
    }
   ],
   "source": [
    "#Create the string pairs and the string lists\n",
    "# train_zh_pairs, zh_train, zh_en_train = prepareData(input_zh, output_zh_en, 'train')\n",
    "# val_zh_pairs, zh_val, zh_en_val = prepareData(input_zh, output_zh_en, 'dev')\n",
    "# test_zh_pairs, zh_test, zh_en_test = prepareData(input_zh, output_zh_en, 'test')\n",
    "\n",
    "train_vi_pairs, vi_train, vi_en_train = prepareData(input_vi, output_vi_en, 'train')\n",
    "val_vi_pairs, vi_val, vi_en_val = prepareData(input_vi, output_vi_en, 'dev')\n",
    "test_vi_pairs, vi_test, vi_en_test = prepareData(input_vi, output_vi_en, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['khi toi 11 tuoi , toi nho mot buoi sang toi thuc_day khi nghe tieng han_hoan trong can nha cua toi .',\n",
       " 'when i was i remember waking up one morning to the sound of joy in my house .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(val_vi_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zh_idx_train, zh_en_idx_train = indexesFromSentences(input_zh, output_zh_en, train_zh_pairs)\n",
    "# zh_idx_val, zh_en_idx_val = indexesFromSentences(input_zh, output_zh_en, val_zh_pairs)\n",
    "# zh_idx_test, zh_en_idx_test = indexesFromSentences(input_zh, output_zh_en, test_zh_pairs)\n",
    "\n",
    "vi_idx_train, vi_en_idx_train = indexesFromSentences(input_vi, output_vi_en, train_vi_pairs)\n",
    "vi_idx_val, vi_en_idx_val = indexesFromSentences(input_vi, output_vi_en, val_vi_pairs)\n",
    "vi_idx_test, vi_en_idx_test = indexesFromSentences(input_vi, output_vi_en, test_vi_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zh_train_pairs = [[zh_idx_train[i], zh_en_idx_train[i]] for i in range(len(zh_idx_train))]\n",
    "# zh_val_pairs = [[zh_idx_val[i], zh_en_idx_val[i]] for i in range(len(zh_idx_val))]\n",
    "# zh_test_pairs= [[zh_idx_test[i], zh_en_idx_test[i]] for i in range(len(zh_idx_test))]\n",
    "vi_train_pairs = [[vi_idx_train[i], vi_en_idx_train[i]] for i in range(len(vi_idx_train))]\n",
    "vi_val_pairs = [[vi_idx_val[i], vi_en_idx_val[i]] for i in range(len(vi_idx_val))]\n",
    "vi_test_pairs = [[vi_idx_test[i], vi_en_idx_test[i]] for i in range(len(vi_idx_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(zh_train_pairs, open('./data/zh_train_pairs.p', 'wb'))\n",
    "# pkl.dump(zh_val_pairs, open('./data/zh_val_pairs.p', 'wb'))\n",
    "# pkl.dump(zh_test_pairs, open('./data/zh_test_pairs.p', 'wb'))\n",
    "\n",
    "# pkl.dump(vi_train_pairs, open('./data/vi_train_pairs.p', 'wb'))\n",
    "# pkl.dump(vi_val_pairs, open('./data/vi_val_pairs.p', 'wb'))\n",
    "# pkl.dump(vi_test_pairs, open('./data/vi_test_pairs.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 104\n"
     ]
    }
   ],
   "source": [
    "max_val_len = 0\n",
    "second_len = 0\n",
    "for pair in vi_val_pairs:\n",
    "    if max_val_len < len(pair[0]):\n",
    "        second_len = max_val_len\n",
    "        max_val_len = len(pair[0])\n",
    "\n",
    "print(max_val_len, second_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For training data, we have max-len as 100: train: 133038/133316, val: 1268/1268, test: 1553/1553\n",
    "#For training data, we have max-len as 80: train: 132789/133316, val: 1267/1268, test: 1552/1553\n",
    "vi_train_pairs_cleaned= []\n",
    "vi_val_pairs_cleaned = []\n",
    "vi_test_pairs_cleaned = []\n",
    "MAX_LENGTH = 80\n",
    "for vi_list in vi_train_pairs:\n",
    "    if len(vi_list[0])<=MAX_LENGTH and len(vi_list[1]) <= MAX_LENGTH:\n",
    "        vi_train_pairs_cleaned.append(vi_list)\n",
    "        \n",
    "for vi_list in vi_val_pairs:\n",
    "    if len(vi_list[0])<=MAX_LENGTH and len(vi_list[1]) <= MAX_LENGTH:\n",
    "        vi_val_pairs_cleaned.append(vi_list)\n",
    "\n",
    "for vi_list in vi_test_pairs:\n",
    "    if len(vi_list[0])<=MAX_LENGTH and len(vi_list[1]) <= MAX_LENGTH:\n",
    "        vi_test_pairs_cleaned.append(vi_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133166"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132318"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_train_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_val_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1549"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_test_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# # pkl.dump(zh_train_pairs_cleaned, open('./data/zh_train_pairs_cleaned.p', 'wb'))\n",
    "# # pkl.dump(zh_val_pairs_cleaned, open('./data/zh_val_pairs_cleaned.p', 'wb'))\n",
    "# # pkl.dump(zh_test_pairs_cleaned, open('./data/zh_test_pairs_cleaned.p', 'wb'))\n",
    "\n",
    "# pkl.dump(vi_train_pairs_cleaned, open('./data/vi_train_pairs_cleaned.p', 'wb'))\n",
    "# pkl.dump(vi_val_pairs_cleaned, open('./data/vi_val_pairs_cleaned.p', 'wb'))\n",
    "# pkl.dump(vi_test_pairs_cleaned, open('./data/vi_test_pairs_cleaned.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# #loading data\n",
    "# # zh_train_pairs_cleaned = pkl.load(open('./data/zh_train_pairs_cleaned.p', 'rb'))\n",
    "# # zh_val_pairs_cleaned = pkl.load(open('./data/zh_val_pairs_cleaned.p', 'rb'))\n",
    "# # zh_test_pairs_cleaned = pkl.load(open('./data/zh_test_pairs_cleaned.p', 'rb'))\n",
    "\n",
    "# vi_train_pairs_cleaned = pkl.load(open('./data/vi_train_pairs_cleaned.p', 'rb'))\n",
    "# vi_val_pairs_cleaned = pkl.load(open('./data/vi_val_pairs_cleaned.p', 'rb'))\n",
    "# vi_test_pairs_cleaned = pkl.load(open('./data/vi_test_pairs_cleaned.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, pairs):#Needs the index pairs\n",
    "        self.pairs = pairs\n",
    "#         self.input_lang = input_lang\n",
    "#         self.output_lang = output_lang\n",
    "        self.input_seqs = [pairs[i][0] for i in range(len(self.pairs))]\n",
    "        self.output_seqs = [pairs[i][1] for i in range(len(self.pairs))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)#Returning number of pairs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_seq = self.input_seqs[index]\n",
    "        output_seq = self.output_seqs[index]\n",
    "        return [input_seq, len(input_seq), output_seq, len(output_seq)]\n",
    "    \n",
    "def vocab_collate_func(batch):\n",
    "    #Reference: lab8_3_mri\n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq) for seq in seqs]\n",
    "#         padded_seqs = torch.zeros(len(seqs), max(lens)).long()\n",
    "        padded_seqs = torch.zeros(len(seqs), MAX_LENGTH).long()\n",
    "        for i, seq in enumerate(seqs):\n",
    "            end = lens[i]\n",
    "            padded_seqs[i, :end] = torch.LongTensor(seq[:end])\n",
    "        return padded_seqs, lens\n",
    "    \n",
    "    batch_input_seqs = [datum[0] for datum in batch]\n",
    "    batch_output_seqs = [datum[2] for datum in batch]\n",
    "    #batch_input_length = [datum[1] for datum in batch]\n",
    "    #batch_output_length = [datum[3] for datum in batch]\n",
    "\n",
    "    sorted_pairs = sorted(zip(batch_input_seqs, batch_output_seqs), key=lambda x: len(x[0]), reverse = True)\n",
    "    in_seq_sorted, out_seq_sorted = zip(*sorted_pairs)\n",
    "    \n",
    "    padded_input,input_lens = _pad_sequences(in_seq_sorted)\n",
    "    padded_output,output_lens = _pad_sequences(out_seq_sorted)\n",
    "    \n",
    "    input_list = torch.from_numpy(np.array(padded_input))\n",
    "    input_length = torch.LongTensor(input_lens)\n",
    "    output_list = torch.from_numpy(np.array(padded_output))\n",
    "    output_length = torch.LongTensor(output_lens)\n",
    "    \n",
    "    if CUDA:\n",
    "        input_list = input_list.cuda()\n",
    "        output_list = output_list.cuda()\n",
    "        input_length = input_length.cuda()\n",
    "        output_length = output_length.cuda()\n",
    "            \n",
    "    return [input_list, input_length, output_list, output_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "'''\n",
    "NMTDataset needs index pairs, need to call indexesFromPairs functions beforehand\n",
    "The dataLoader is sorted according to length of the input_length, and padded to\n",
    "max length of input and output list repectively\n",
    "TODO: output_list is not sorted, hence need to sort (maybe) in the rnn sequence.\n",
    "'''\n",
    "# train_zh_dataset = NMTDataset(zh_train_pairs_cleaned, input_zh, output_zh_en)\n",
    "# train_vi_dataset = NMTDataset(vi_train_pairs_cleaned, input_vi, output_vi_en)\n",
    "# val_zh_dataset = NMTDataset(zh_val_pairs_cleaned, input_zh, output_zh_en)\n",
    "# val_vi_dataset = NMTDataset(vi_val_pairs_cleaned, input_vi, output_vi_en)\n",
    "# test_zh_dataset = NMTDataset(zh_test_pairs_cleaned, input_zh, output_zh_en)\n",
    "# test_vi_dataset = NMTDataset(vi_test_pairs_cleaned, input_vi, output_vi_en)\n",
    "\n",
    "# train_zh_dataset = NMTDataset(zh_train_pairs_cleaned)\n",
    "train_vi_dataset = NMTDataset(vi_train_pairs_cleaned)\n",
    "# val_zh_dataset = NMTDataset(zh_val_pairs_cleaned)\n",
    "val_vi_dataset = NMTDataset(vi_val_pairs_cleaned)\n",
    "# test_zh_dataset = NMTDataset(zh_test_pairs_cleaned)\n",
    "test_vi_dataset = NMTDataset(vi_test_pairs_cleaned)\n",
    "\n",
    "\n",
    "# train_zh_loader = torch.utils.data.DataLoader(dataset = train_zh_dataset, \n",
    "#                                           batch_size = BATCH_SIZE,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = True)\n",
    "\n",
    "train_vi_loader = torch.utils.data.DataLoader(dataset = train_vi_dataset, \n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = True)\n",
    "\n",
    "#Will use batch size 1 for validation and test since the sentence will be translated one by one\n",
    "# val_zh_loader = torch.utils.data.DataLoader(dataset = val_zh_dataset, \n",
    "#                                           batch_size = 1,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = False)\n",
    "val_vi_loader = torch.utils.data.DataLoader(dataset = val_vi_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "# test_zh_loader = torch.utils.data.DataLoader(dataset = test_zh_dataset, \n",
    "#                                           batch_size = 1,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = False)\n",
    "test_vi_loader = torch.utils.data.DataLoader(dataset = test_vi_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "#Input_batch in size Batch x maxLen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (input_list, input_length, output_list, output_length) in enumerate(val_zh_loader):\n",
    "#     if i== 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_list.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here for the constant definition\n",
    "# MAX_SENTENCE_LENGTH = 10\n",
    "hidden_size = 256\n",
    "max_length = 10\n",
    "BATCH_SIZE = 3\n",
    "TEST_BATCH_SIZE = 3\n",
    "CLIP = 50\n",
    "TEACHER_RATIO = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# #loading data\n",
    "# # loaded_zh_embeddings = pkl.load(open(ftdir+'zh_embeddings.p', 'rb'))\n",
    "# loaded_vi_embeddings = pkl.load(open(ftdir+'vi_embeddings.p', 'rb'))\n",
    "# loaded_en_embeddings = pkl.load(open(ftdir+'en_embeddings.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA = False\n",
    "# loaded_zh_embeddings = torch.from_numpy(loaded_zh_embeddings).float()\n",
    "loaded_vi_embeddings = torch.from_numpy(loaded_vi_embeddings).float()\n",
    "loaded_en_embeddings = torch.from_numpy(loaded_en_embeddings).float()\n",
    "\n",
    "if CUDA:\n",
    "#     loaded_zh_embeddings = loaded_zh_embeddings.cuda()\n",
    "    loaded_vi_embeddings = loaded_vi_embeddings.cuda()\n",
    "    loaded_en_embeddings = loaded_en_embeddings.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_size=emb_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(loaded_vi_embeddings, freeze=True)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_list, hidden):\n",
    "        embedded = self.embedding(input_list)\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "#         output, hidden = self.gru(packed, hidden)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embed_size=emb_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(loaded_en_embeddings, freeze=True)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input)        \n",
    "        output = F.relu(output)        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "encoder_test = EncoderRNN(hidden_size).to(device)\n",
    "decoder_test = DecoderRNN(hidden_size, len(vi_ordered_words)).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i, (input_list,input_length,output_list, output_length) in enumerate(train_vi_loader):\n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "            \n",
    "    encoder_hidden = encoder_test.initHidden(batch_size)\n",
    "    encoder_output, encoder_hidden = encoder_test(input_list, encoder_hidden)\n",
    "#     encoder_output, encoder_hidden = batch_encoder(input_list, input_length, encoder_hidden)\n",
    "    \n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "#     decoder_input = torch.tensor([[SOS_TOKEN]]*batch_size, device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "#     decoder_hidden = encoder_hidden[:batch_decoder.n_layers]\n",
    "\n",
    "    loss = 0\n",
    "    for di in range(max_output_length):\n",
    "\n",
    "        decoder_output, decoder_hidden = decoder_test(\n",
    "            decoder_input, decoder_hidden)\n",
    "\n",
    "\n",
    "        loss += criterion(decoder_output, output_list[:,di])\n",
    "        decoder_input = output_list[:,di].unsqueeze(0) \n",
    "    loss.backward()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referenced from lab8 1nmt and modified \n",
    "teacher_forcing_ratio = 0.5\n",
    "def batch_train(input_list, input_length, output_list,output_length, \n",
    "                batch_encoder, batch_decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    '''\n",
    "    param: @attention is a Boolean variable indicating whether using attention\n",
    "    '''\n",
    "    batch_encoder.train()\n",
    "    batch_decoder.train()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "    \n",
    "#     batch_size = input_list.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = batch_encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_outputs, encoder_hidden = batch_encoder(input_list, encoder_hidden)\n",
    "\n",
    "    #Initialize for decoding process\n",
    "    curr_batch = input_list.size(0)#Take the current batch size\n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "    \n",
    "#     decoder_hidden = encoder_hidden[:batch_decoder.n_layers]#Bidirectional summoned\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden = batch_decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            decoder_input = output_list[:,di].unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "\n",
    "    else:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden = batch_decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "            \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "learning_rate = 0.01\n",
    "\n",
    "encoder = EncoderRNN(hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, len(vi_ordered_words)).to(device)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i, (input_list,input_length,output_list, output_length) in enumerate(train_vi_loader):\n",
    "    loss = batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference lab8 1-nmt\n",
    "def greedy_evaluate(val_loader, encoder, decoder, en_id2words ):\n",
    "    #Will generate sentences 1 by 1. \n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    decoded_words_all = []\n",
    "              \n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for i, (input_list, input_length, output_list, output_length) in enumerate(val_loader):\n",
    "            if i %100 == 0:\n",
    "                print(\"%d/%d\"%(i,len(val_loader)))\n",
    "                \n",
    "            batch_size, max_input_length = input_list.size()\n",
    "            max_output_length = output_list.size(1)\n",
    "            \n",
    "            #    break\n",
    "            #batch_size, max_len = output_list.size()\n",
    "#             print(input_list.size())\n",
    "\n",
    "#         encoder_hidden = batch_encoder.initHidden(batch_size)\n",
    "\n",
    "#     encoder_outputs, encoder_hidden = batch_encoder(input_list, encoder_hidden)\n",
    "\n",
    "#     #Initialize for decoding process\n",
    "#     curr_batch = input_list.size(0)#Take the current batch size\n",
    "#     decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "    \n",
    "# #     decoder_hidden = encoder_hidden[:batch_decoder.n_layers]#Bidirectional summoned\n",
    "#     decoder_hidden = encoder_hidden\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_outputs, encoder_hidden = encoder(input_list, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "#             decoder_input = torch.tensor([[SOS_TOKEN]], device=device)  # SOS\n",
    "            # decode the context vector\n",
    "            decoder_hidden = encoder_hidden\n",
    "#             decoder_hidden = encoder_hidden[:decoder.n_layers] # decoder starts from the last encoding sentence\n",
    "            # output of this function\n",
    "            decoded_words = []\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input.reshape(1, batch_size), decoder_hidden)\n",
    "\n",
    "                top_score, topi = decoder_output.data.topk(1)\n",
    "                decoded_words.append(en_id2words[topi.item()])\n",
    "                if topi.item() == EOS_TOKEN:\n",
    "                    break\n",
    "                else:\n",
    "                    decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "                    \n",
    "            decoded_words_all.append(decoded_words)\n",
    "\n",
    "        return decoded_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_words_all, decoder_attention_all = greedy_attn_evaluate(val_zh_loader, pre_encoder, attn_decoder, en_id2words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(decoded_words_all):\n",
    "    cleaned_decoded_words_all = []\n",
    "    \n",
    "    for sentence in decoded_words_all:\n",
    "        cleaned_sentence = []\n",
    "        for word in sentence:\n",
    "            if word == '<PAD>':\n",
    "                continue\n",
    "            else:\n",
    "                cleaned_sentence.append(word)\n",
    "        if cleaned_sentence[-1] != '<EOS>':\n",
    "            cleaned_sentence.append(' <EOS>')\n",
    "            \n",
    "        cleaned_decoded_words_all.append(cleaned_sentence)\n",
    "        \n",
    "    return cleaned_decoded_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translate the test and val lists back to english\n",
    "def en_translate(index_list, en_id2words):\n",
    "    translated_sentence_list = []\n",
    "    for sentence in index_list:\n",
    "        translated_sentence = []\n",
    "        for index in sentence:\n",
    "            translated_sentence.append(en_id2words[index])\n",
    "        #translated_sentence.append('<EOS>')\n",
    "        translated_sentence_list.append(translated_sentence)\n",
    "    return translated_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_words_list = post_process(decoded_words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_words_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when',\n",
       " 'i',\n",
       " 'was',\n",
       " 'little',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'my',\n",
       " 'country',\n",
       " 'was',\n",
       " 'the',\n",
       " 'best',\n",
       " 'on',\n",
       " 'the',\n",
       " 'planet',\n",
       " 'and',\n",
       " 'i',\n",
       " 'grew',\n",
       " 'up',\n",
       " 'singing',\n",
       " 'a',\n",
       " 'song',\n",
       " 'called',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'envy',\n",
       " '.',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_en_val_list = [pair[1] for pair in vi_val_pairs_cleaned]\n",
    "translated_sentence_list = en_translate(vi_en_val_list, en_id2words)\n",
    "translated_sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference LAB8 1-nmt\n",
    "model_path = './model/'\n",
    "def TrainIters(train_loader, val_loader, encoder, decoder, n_iters, val_translated_list,\n",
    "                   print_every=100, plot_every=100, eval_every=500, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    epoch = 0\n",
    "    epoch_total = n_iters*len(train_loader)\n",
    "    \n",
    "#     loss = 0\n",
    "    \n",
    "    for iter in range(n_iters):\n",
    "        print_loss_total = 0  # Reset every print_every\n",
    "        plot_loss_total = 0  # Reset every plot_every\n",
    "        #print(\"Epoch {}/{}\".format(i+1, n_epochs))\n",
    "        for i, (input_list,input_length,output_list, output_length) in enumerate(train_loader):\n",
    "            loss = batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "#             if i > 0 and i % eval_every == 0:\n",
    "#                 decoded_val, decoder_attentions = greedy_attn_evaluate(val_loader, encoder, decoder, en_id2words)\n",
    "#                 decoded_clean = post_process(decoded_val)\n",
    "#                 print('bleu score is {}'.format(raw_corpus_bleu(decoded_val, val_translated_list).score))\n",
    "\n",
    "            if i > 0 and i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / epoch_total),\n",
    "                                             epoch, epoch / epoch_total * 100, print_loss_avg))\n",
    "\n",
    "            if i > 0 and i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "            epoch += 1\n",
    "            \n",
    "        torch.save(encoder.state_dict(), model_path + \"encoder_rnn_\"+str(start)+\".pth\")\n",
    "        torch.save(decoder.state_dict(), model_path + \"decoder_rnn_\"+str(start)+\".pth\")\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 4s (- 87m 53s) (100 1%) 96.2952\n",
      "2m 8s (- 86m 33s) (200 2%) 97.6171\n",
      "3m 12s (- 85m 17s) (300 3%) 96.1381\n",
      "4m 16s (- 84m 0s) (400 4%) 90.3176\n",
      "5m 20s (- 82m 56s) (500 6%) 93.8625\n",
      "6m 24s (- 81m 52s) (600 7%) 96.0208\n",
      "7m 28s (- 80m 48s) (700 8%) 95.6722\n",
      "8m 32s (- 79m 43s) (800 9%) 92.9771\n",
      "9m 36s (- 78m 42s) (900 10%) 99.5170\n",
      "10m 40s (- 77m 39s) (1000 12%) 97.3434\n",
      "11m 44s (- 76m 33s) (1100 13%) 95.1725\n",
      "12m 48s (- 75m 28s) (1200 14%) 95.1142\n",
      "13m 52s (- 74m 22s) (1300 15%) 91.1673\n",
      "14m 56s (- 73m 19s) (1400 16%) 94.3412\n",
      "16m 0s (- 72m 14s) (1500 18%) 92.9831\n",
      "17m 4s (- 71m 9s) (1600 19%) 91.9231\n",
      "18m 8s (- 70m 5s) (1700 20%) 94.9904\n",
      "19m 12s (- 69m 2s) (1800 21%) 98.1314\n",
      "20m 16s (- 67m 59s) (1900 22%) 95.4475\n",
      "21m 20s (- 66m 54s) (2000 24%) 93.8922\n",
      "22m 24s (- 65m 50s) (2100 25%) 95.0206\n",
      "23m 28s (- 64m 46s) (2200 26%) 92.0465\n",
      "24m 32s (- 63m 42s) (2300 27%) 96.4450\n",
      "25m 36s (- 62m 37s) (2400 29%) 94.1764\n",
      "26m 40s (- 61m 33s) (2500 30%) 95.6303\n",
      "27m 44s (- 60m 29s) (2600 31%) 92.6721\n",
      "28m 49s (- 59m 26s) (2700 32%) 99.7239\n",
      "29m 53s (- 58m 23s) (2800 33%) 96.7806\n",
      "30m 56s (- 57m 18s) (2900 35%) 94.3645\n",
      "32m 1s (- 56m 14s) (3000 36%) 91.8568\n",
      "33m 4s (- 55m 10s) (3100 37%) 94.3593\n",
      "34m 8s (- 54m 5s) (3200 38%) 91.7896\n",
      "35m 12s (- 53m 1s) (3300 39%) 95.4703\n",
      "36m 16s (- 51m 58s) (3400 41%) 96.5695\n",
      "37m 20s (- 50m 53s) (3500 42%) 90.5877\n",
      "38m 24s (- 49m 49s) (3600 43%) 96.8569\n",
      "39m 28s (- 48m 45s) (3700 44%) 92.6413\n",
      "40m 32s (- 47m 40s) (3800 45%) 94.9792\n",
      "41m 36s (- 46m 36s) (3900 47%) 96.0770\n",
      "42m 40s (- 45m 33s) (4000 48%) 95.0619\n",
      "43m 43s (- 44m 28s) (4100 49%) 89.3217\n",
      "45m 10s (- 43m 2s) (4235 51%) 93.8324\n",
      "46m 14s (- 41m 58s) (4335 52%) 89.5034\n",
      "47m 18s (- 40m 54s) (4435 53%) 93.0074\n",
      "48m 22s (- 39m 50s) (4535 54%) 91.7294\n",
      "49m 26s (- 38m 46s) (4635 56%) 92.0630\n",
      "50m 30s (- 37m 42s) (4735 57%) 90.8188\n",
      "51m 34s (- 36m 38s) (4835 58%) 89.0580\n",
      "52m 38s (- 35m 34s) (4935 59%) 93.1499\n",
      "53m 42s (- 34m 30s) (5035 60%) 94.3023\n",
      "54m 46s (- 33m 26s) (5135 62%) 89.1051\n",
      "55m 50s (- 32m 22s) (5235 63%) 91.9617\n",
      "56m 54s (- 31m 18s) (5335 64%) 90.5868\n",
      "57m 58s (- 30m 14s) (5435 65%) 93.8483\n",
      "59m 2s (- 29m 10s) (5535 66%) 93.3740\n",
      "60m 6s (- 28m 6s) (5635 68%) 94.6367\n",
      "61m 10s (- 27m 2s) (5735 69%) 93.7214\n",
      "62m 15s (- 25m 58s) (5835 70%) 95.2912\n",
      "63m 19s (- 24m 54s) (5935 71%) 94.0867\n",
      "64m 23s (- 23m 50s) (6035 72%) 93.1097\n",
      "65m 26s (- 22m 46s) (6135 74%) 90.5350\n",
      "66m 30s (- 21m 42s) (6235 75%) 89.9114\n",
      "67m 34s (- 20m 38s) (6335 76%) 92.1609\n",
      "68m 38s (- 19m 34s) (6435 77%) 91.1940\n",
      "69m 42s (- 18m 30s) (6535 79%) 91.7714\n",
      "70m 46s (- 17m 26s) (6635 80%) 91.7135\n",
      "71m 50s (- 16m 22s) (6735 81%) 93.4178\n",
      "72m 54s (- 15m 18s) (6835 82%) 90.4117\n",
      "73m 58s (- 14m 14s) (6935 83%) 91.7056\n",
      "75m 2s (- 13m 10s) (7035 85%) 90.6718\n",
      "76m 5s (- 12m 6s) (7135 86%) 90.2749\n",
      "77m 9s (- 11m 2s) (7235 87%) 91.7310\n",
      "78m 12s (- 9m 58s) (7335 88%) 88.4199\n",
      "79m 17s (- 8m 54s) (7435 89%) 93.0462\n",
      "80m 21s (- 7m 50s) (7535 91%) 92.9391\n",
      "81m 25s (- 6m 46s) (7635 92%) 92.7113\n",
      "82m 29s (- 5m 42s) (7735 93%) 90.9839\n",
      "83m 33s (- 4m 38s) (7835 94%) 90.9316\n",
      "84m 36s (- 3m 34s) (7935 95%) 90.6631\n",
      "85m 41s (- 2m 30s) (8035 97%) 94.5072\n",
      "86m 45s (- 1m 26s) (8135 98%) 92.8886\n",
      "87m 49s (- 0m 22s) (8235 99%) 94.6596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_size = 300\n",
    "\n",
    "# encoder = EncoderRNN(hidden_size).to(device)\n",
    "# decoder = DecoderRNN(hidden_size, len(vi_ordered_words)).to(device)\n",
    "# pre_encoder = PreBatchEncoderRNN(loaded_vi_embeddings, emb_size, hidden_size, train_vi_loader.batch_size).to(device)\n",
    "# attn_decoder = PreAttnDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), train_vi_loader.batch_size).to(device)\n",
    "\n",
    "plot_losses = TrainIters(train_vi_loader, val_vi_loader, encoder, decoder, 2,\n",
    "               None, print_every=100, learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(model_path + \"vi-loss\", plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1262\n",
      "100/1262\n",
      "200/1262\n",
      "300/1262\n",
      "400/1262\n",
      "500/1262\n",
      "600/1262\n",
      "700/1262\n",
      "800/1262\n",
      "900/1262\n",
      "1000/1262\n",
      "1100/1262\n",
      "1200/1262\n"
     ]
    }
   ],
   "source": [
    "decoded_val = greedy_evaluate(val_vi_loader, encoder, decoder, en_id2words)\n",
    "decoded_clean = post_process(decoded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_bleu,raw_corpus_bleu\n",
    "\n",
    "def bleu_score(predicted_list,translated_list):\n",
    "    predicted_list_nopad = []\n",
    "    for ii in range(len(predicted_list)):\n",
    "        line = ''\n",
    "        for jj in predicted_list[ii]:\n",
    "            if jj != '<pad>':\n",
    "                line = line + ' ' + jj\n",
    "        predicted_list_nopad.append(line)\n",
    "    labels = []\n",
    "    for ii in range(len(translated_list)):\n",
    "        line = ''\n",
    "        for jj in translated_list[ii]:\n",
    "            if jj != '<pad>':\n",
    "                line = line + ' ' + jj\n",
    "        labels.append(line)\n",
    "    #print(len(labels))\n",
    "    #print(len(predicted_list_nopad))\n",
    "    print('bleu score for test dataset:', corpus_bleu(predicted_list_nopad, [labels]).score)\n",
    "    print('bleu score for test dataset [raw]:', raw_corpus_bleu(predicted_list_nopad, [labels]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for test dataset: 12.820060448125922\n",
      "bleu score for test dataset [raw]: 3.4357083784199354\n"
     ]
    }
   ],
   "source": [
    "bleu_score(decoded_clean,translated_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for test dataset: 13.244067757436477\n",
      "bleu score for test dataset [raw]: 3.1149446308128703\n"
     ]
    }
   ],
   "source": [
    "bleu_score(decoded_clean,translated_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so', 'there', 's', 'this', '.', 'this', '.', '.', '<EOS>']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(decoded_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = timer()\n",
    "i = 0\n",
    "for batch in train_zh_loader:\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-80f084b89653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshowPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_losses' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
