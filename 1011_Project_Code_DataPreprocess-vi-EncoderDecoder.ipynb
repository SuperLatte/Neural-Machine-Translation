{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "from sacrebleu import raw_corpus_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants here\n",
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 3\n",
    "words_to_load = 80000\n",
    "emb_size = 300\n",
    "wiki_size = 300\n",
    "CUDA = True\n",
    "MAX_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.getcwd()\n",
    "datadir\n",
    "ftdir = '/scratch/yz4499/fasttext/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained word embeddings:\n",
    "Reference: https://fasttext.cc/docs/en/pretrained-vectors.html\n",
    "\n",
    "@article{bojanowski2017enriching,\n",
    "  title={Enriching Word Vectors with Subword Information},\n",
    "  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},\n",
    "  journal={Transactions of the Association for Computational Linguistics},\n",
    "  volume={5},\n",
    "  year={2017},\n",
    "  issn={2307-387X},\n",
    "  pages={135--146}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference Lab4 HW2\n",
    "# datadir = os.getcwd()\n",
    "words_to_load = 50000\n",
    "# with open(datadir + '/data/wiki-news-300d-1M.vec') as f:\n",
    "with open(ftdir + 'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_en_embeddings = np.zeros(((words_to_load+4), wiki_size))\n",
    "    en_word2id = {}\n",
    "    en_id2words = {}\n",
    "    \n",
    "    en_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    en_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    en_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    en_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    en_word2id['<PAD>'] = PAD_TOKEN\n",
    "    en_word2id['<SOS>'] = SOS_TOKEN\n",
    "    en_word2id['<EOS>'] = EOS_TOKEN\n",
    "    en_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    en_ordered_words= []\n",
    "    en_ordered_words.append('<PAD>')\n",
    "    en_ordered_words.append('<SOS>')\n",
    "    en_ordered_words.append('<EOS>')\n",
    "    en_ordered_words.append('<UNK>')\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load:\n",
    "            break\n",
    "        if i ==0:#Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        #print(len(s))\n",
    "        loaded_en_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        en_word2id[s[0]] = i+4 #for extra pad and unk eos and unk\n",
    "        en_id2words[i+4] = s[0]\n",
    "        en_ordered_words.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 0 has wrong dimension, hence skipped\n"
     ]
    }
   ],
   "source": [
    "#Reference Lab4 HW2\n",
    "#Over 200000 loaded words, 58 has wrong dimensions\n",
    "words_to_load = 50000\n",
    "# datadir = os.getcwd()\n",
    "with open(ftdir + 'cc.vi.300.vec') as f:\n",
    "    loaded_vi_embeddings = np.zeros(((words_to_load+4),wiki_size))\n",
    "    vi_word2id = {}\n",
    "    vi_id2words = {}\n",
    "    \n",
    "    vi_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    vi_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    vi_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    vi_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    vi_word2id['<PAD>'] = PAD_TOKEN\n",
    "    vi_word2id['<SOS>'] = SOS_TOKEN\n",
    "    vi_word2id['<EOS>'] = EOS_TOKEN\n",
    "    vi_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    vi_ordered_words= []\n",
    "    vi_ordered_words.append('<PAD>')\n",
    "    vi_ordered_words.append('<SOS>')\n",
    "    vi_ordered_words.append('<EOS>')\n",
    "    vi_ordered_words.append('<UNK>')\n",
    "    wrong_dim = 0;\n",
    "    for i, line in enumerate(f):\n",
    "        #print(line)\n",
    "        if i >= words_to_load:\n",
    "            break;\n",
    "        if i == 0: #Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        if len(s) != 301:\n",
    "            wrong_dim += 1#Skip the wrong dimension one\n",
    "            continue;\n",
    "        loaded_vi_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        vi_word2id[s[0]] = i+4 #for extra pad and unk \n",
    "        vi_id2words[i+4] = s[0]\n",
    "        vi_ordered_words.append(s[0])\n",
    "    print('In total {} has wrong dimension, hence skipped'.format(wrong_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(loaded_zh_embeddings, open(ftdir+'zh_embeddings.p', 'wb'))\n",
    "# pkl.dump(loaded_en_embeddings, open(ftdir+'en_embeddings.p', 'wb'))\n",
    "# pkl.dump(loaded_vi_embeddings, open(ftdir+'vi_embeddings.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name, emb_word2id, emb_id2word, emb_ordered_words):\n",
    "        self.name = name\n",
    "        self.word2index = emb_word2id\n",
    "        self.word2count = {}\n",
    "        self.index2word = emb_id2word #Dict\n",
    "        self.n_words = 4  # Count SOS and EOS +(batch: pad and unk)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count:\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "#Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s, lang):\n",
    "    if lang == \"en\":\n",
    "        s = s.replace(\"&apos;\", \"\").replace(\"&quot;\", \"\")\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #This line is commented out since it will not properly deal with Chinese Letters\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "#reference: LAB4 hw2\n",
    "def indexesFromSentences(lang1, lang2, pairs):\n",
    "    id_list1 = []\n",
    "    id_list2 = []\n",
    "    for i in range(len(pairs)):\n",
    "        sentence1 = pairs[i][0]\n",
    "        sentence2 = pairs[i][1]\n",
    "        \n",
    "        sentence1 = sentence1.replace('quot','')\n",
    "        sentence1 = sentence1.replace('apos', '')\n",
    "        sentence2 = sentence2.replace('quot','')\n",
    "        sentence2 = sentence2.replace('apos', '')\n",
    "        #If either sentence is empty, then remove the pair\n",
    "        if sentence1 == '' or sentence2 == '':\n",
    "            continue;\n",
    "        \n",
    "        id_sentence1 = [lang1.word2index[word] if word in lang1.word2index else UNK_TOKEN \n",
    "                        for word in sentence1.split()] + [EOS_TOKEN]\n",
    "        id_list1.append(id_sentence1)\n",
    "        id_sentence2 = [lang2.word2index[word] if word in lang2.word2index else UNK_TOKEN \n",
    "                        for word in sentence2.split()] + [EOS_TOKEN]\n",
    "        id_list2.append(id_sentence2)\n",
    "        \n",
    "   \n",
    "        \n",
    "    return id_list1,id_list2\n",
    "\n",
    "# def sentence2id(sentence_list):\n",
    "#     id_list = []\n",
    "#     for sentence in sentence_list:\n",
    "#         sentence_id_list = [word2id[word] if word in word2id else UNK_IDX for word in sentence]\n",
    "#         id_list.append(sentence_id_list)\n",
    "#     return id_list\n",
    "\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_TOKEN)\n",
    "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "#     return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "# def filterPair(p):\n",
    "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "#         len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "#         p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "# def filterPairs(pairs):\n",
    "#     return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, category, reverse = False):#category = ['train', 'dev','test]\n",
    "    print('Reading lines:')\n",
    "    lines1 = open('data/iwslt-' + lang1.name +'-en/' + category +'.tok.'+ lang1.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data1 = [normalizeString(l, lang1.name) for l in lines1]\n",
    "    #data1 = list(filter(None, data1)) # fastest\n",
    "\n",
    "    lines2 = open('data/iwslt-' + lang1.name +'-en/' + category + '.tok.' + lang2.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data2 = [normalizeString(l, lang2.name) for l in lines2]\n",
    "    #Given that data2 is english hence we further normalize\n",
    "    data2 = [re.sub(r\"[^a-zA-Z.!?]+\", r\" \", data) for data in data2]\n",
    "    #data2 = list(filter(None, data2)) # fastest\n",
    "\n",
    "    return data1, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation for CHN to ENG\n",
    "def prepareData(lang1, lang2, category, reverse = False):\n",
    "    data1, data2 = readLangs(lang1, lang2, category, reverse)#Read data returns list of sentences\n",
    "    pairs = [[data1[i], data2[i]] for i in range(len(data1))]\n",
    "    print('Read %s sentence pairs' % len(pairs))\n",
    "    #Count the words\n",
    "    print('Counting words')\n",
    "    for i in range(len(pairs)):\n",
    "        lang1.addSentence(data1[i])\n",
    "        lang2.addSentence(data2[i])\n",
    "\n",
    "    print('Counted Words')\n",
    "    print(lang1.name, lang1.n_words)\n",
    "    print(lang2.name, lang2.n_words)\n",
    "\n",
    "    return pairs, data1, data2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create language object\n",
    "# input_zh = Lang('zh', zh_word2id, zh_id2words, zh_ordered_words)\n",
    "# output_zh_en = Lang('en', en_word2id, en_id2words, en_ordered_words)\n",
    "input_vi = Lang('vi', vi_word2id, vi_id2words, vi_ordered_words)\n",
    "output_vi_en = Lang('en', en_word2id, en_id2words, en_ordered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines:\n",
      "Read 133317 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "vi 30768\n",
      "en 41271\n",
      "Reading lines:\n",
      "Read 1268 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "vi 30916\n",
      "en 41434\n",
      "Reading lines:\n",
      "Read 1553 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "vi 31057\n",
      "en 41598\n"
     ]
    }
   ],
   "source": [
    "#Create the string pairs and the string lists\n",
    "# train_zh_pairs, zh_train, zh_en_train = prepareData(input_zh, output_zh_en, 'train')\n",
    "# val_zh_pairs, zh_val, zh_en_val = prepareData(input_zh, output_zh_en, 'dev')\n",
    "# test_zh_pairs, zh_test, zh_en_test = prepareData(input_zh, output_zh_en, 'test')\n",
    "\n",
    "train_vi_pairs, vi_train, vi_en_train = prepareData(input_vi, output_vi_en, 'train')\n",
    "val_vi_pairs, vi_val, vi_en_val = prepareData(input_vi, output_vi_en, 'dev')\n",
    "test_vi_pairs, vi_test, vi_en_test = prepareData(input_vi, output_vi_en, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['khi toi 11 tuoi , toi nho mot buoi sang toi thuc_day khi nghe tieng han_hoan trong can nha cua toi .',\n",
       " 'when i was i remember waking up one morning to the sound of joy in my house .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(val_vi_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zh_idx_train, zh_en_idx_train = indexesFromSentences(input_zh, output_zh_en, train_zh_pairs)\n",
    "# zh_idx_val, zh_en_idx_val = indexesFromSentences(input_zh, output_zh_en, val_zh_pairs)\n",
    "# zh_idx_test, zh_en_idx_test = indexesFromSentences(input_zh, output_zh_en, test_zh_pairs)\n",
    "\n",
    "vi_idx_train, vi_en_idx_train = indexesFromSentences(input_vi, output_vi_en, train_vi_pairs)\n",
    "vi_idx_val, vi_en_idx_val = indexesFromSentences(input_vi, output_vi_en, val_vi_pairs)\n",
    "vi_idx_test, vi_en_idx_test = indexesFromSentences(input_vi, output_vi_en, test_vi_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zh_train_pairs = [[zh_idx_train[i], zh_en_idx_train[i]] for i in range(len(zh_idx_train))]\n",
    "# zh_val_pairs = [[zh_idx_val[i], zh_en_idx_val[i]] for i in range(len(zh_idx_val))]\n",
    "# zh_test_pairs= [[zh_idx_test[i], zh_en_idx_test[i]] for i in range(len(zh_idx_test))]\n",
    "vi_train_pairs = [[vi_idx_train[i], vi_en_idx_train[i]] for i in range(len(vi_idx_train))]\n",
    "vi_val_pairs = [[vi_idx_val[i], vi_en_idx_val[i]] for i in range(len(vi_idx_val))]\n",
    "vi_test_pairs = [[vi_idx_test[i], vi_en_idx_test[i]] for i in range(len(vi_idx_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(zh_train_pairs, open('./data/zh_train_pairs.p', 'wb'))\n",
    "# pkl.dump(zh_val_pairs, open('./data/zh_val_pairs.p', 'wb'))\n",
    "# pkl.dump(zh_test_pairs, open('./data/zh_test_pairs.p', 'wb'))\n",
    "\n",
    "# pkl.dump(vi_train_pairs, open('./data/vi_train_pairs.p', 'wb'))\n",
    "# pkl.dump(vi_val_pairs, open('./data/vi_val_pairs.p', 'wb'))\n",
    "# pkl.dump(vi_test_pairs, open('./data/vi_test_pairs.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 104\n"
     ]
    }
   ],
   "source": [
    "max_val_len = 0\n",
    "second_len = 0\n",
    "for pair in vi_val_pairs:\n",
    "    if max_val_len < len(pair[0]):\n",
    "        second_len = max_val_len\n",
    "        max_val_len = len(pair[0])\n",
    "\n",
    "print(max_val_len, second_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For training data, we have max-len as 100: train: 133038/133316, val: 1268/1268, test: 1553/1553\n",
    "#For training data, we have max-len as 80: train: 132789/133316, val: 1267/1268, test: 1552/1553\n",
    "vi_train_pairs_cleaned= []\n",
    "vi_val_pairs_cleaned = []\n",
    "vi_test_pairs_cleaned = []\n",
    "MAX_LENGTH = 80\n",
    "for vi_list in vi_train_pairs:\n",
    "    if len(vi_list[0])<=MAX_LENGTH and len(vi_list[1]) <= MAX_LENGTH:\n",
    "        vi_train_pairs_cleaned.append(vi_list)\n",
    "        \n",
    "for vi_list in vi_val_pairs:\n",
    "    if len(vi_list[0])<=MAX_LENGTH and len(vi_list[1]) <= MAX_LENGTH:\n",
    "        vi_val_pairs_cleaned.append(vi_list)\n",
    "\n",
    "for vi_list in vi_test_pairs:\n",
    "    if len(vi_list[0])<=MAX_LENGTH and len(vi_list[1]) <= MAX_LENGTH:\n",
    "        vi_test_pairs_cleaned.append(vi_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133166"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132318"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_train_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_val_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1549"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vi_test_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# # pkl.dump(zh_train_pairs_cleaned, open('./data/zh_train_pairs_cleaned.p', 'wb'))\n",
    "# # pkl.dump(zh_val_pairs_cleaned, open('./data/zh_val_pairs_cleaned.p', 'wb'))\n",
    "# # pkl.dump(zh_test_pairs_cleaned, open('./data/zh_test_pairs_cleaned.p', 'wb'))\n",
    "\n",
    "# pkl.dump(vi_train_pairs_cleaned, open('./data/vi_train_pairs_cleaned.p', 'wb'))\n",
    "# pkl.dump(vi_val_pairs_cleaned, open('./data/vi_val_pairs_cleaned.p', 'wb'))\n",
    "# pkl.dump(vi_test_pairs_cleaned, open('./data/vi_test_pairs_cleaned.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# #loading data\n",
    "# # zh_train_pairs_cleaned = pkl.load(open('./data/zh_train_pairs_cleaned.p', 'rb'))\n",
    "# # zh_val_pairs_cleaned = pkl.load(open('./data/zh_val_pairs_cleaned.p', 'rb'))\n",
    "# # zh_test_pairs_cleaned = pkl.load(open('./data/zh_test_pairs_cleaned.p', 'rb'))\n",
    "\n",
    "# vi_train_pairs_cleaned = pkl.load(open('./data/vi_train_pairs_cleaned.p', 'rb'))\n",
    "# vi_val_pairs_cleaned = pkl.load(open('./data/vi_val_pairs_cleaned.p', 'rb'))\n",
    "# vi_test_pairs_cleaned = pkl.load(open('./data/vi_test_pairs_cleaned.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, pairs):#Needs the index pairs\n",
    "        self.pairs = pairs\n",
    "#         self.input_lang = input_lang\n",
    "#         self.output_lang = output_lang\n",
    "        self.input_seqs = [pairs[i][0] for i in range(len(self.pairs))]\n",
    "        self.output_seqs = [pairs[i][1] for i in range(len(self.pairs))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)#Returning number of pairs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_seq = self.input_seqs[index]\n",
    "        output_seq = self.output_seqs[index]\n",
    "        return [input_seq, len(input_seq), output_seq, len(output_seq)]\n",
    "    \n",
    "def vocab_collate_func(batch):\n",
    "    #Reference: lab8_3_mri\n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq) for seq in seqs]\n",
    "#         padded_seqs = torch.zeros(len(seqs), max(lens)).long()\n",
    "        padded_seqs = torch.zeros(len(seqs), MAX_LENGTH).long()\n",
    "        for i, seq in enumerate(seqs):\n",
    "            end = lens[i]\n",
    "            padded_seqs[i, :end] = torch.LongTensor(seq[:end])\n",
    "        return padded_seqs, lens\n",
    "    \n",
    "    batch_input_seqs = [datum[0] for datum in batch]\n",
    "    batch_output_seqs = [datum[2] for datum in batch]\n",
    "    #batch_input_length = [datum[1] for datum in batch]\n",
    "    #batch_output_length = [datum[3] for datum in batch]\n",
    "\n",
    "    sorted_pairs = sorted(zip(batch_input_seqs, batch_output_seqs), key=lambda x: len(x[0]), reverse = True)\n",
    "    in_seq_sorted, out_seq_sorted = zip(*sorted_pairs)\n",
    "    \n",
    "    padded_input,input_lens = _pad_sequences(in_seq_sorted)\n",
    "    padded_output,output_lens = _pad_sequences(out_seq_sorted)\n",
    "    \n",
    "    input_list = torch.from_numpy(np.array(padded_input))\n",
    "    input_length = torch.LongTensor(input_lens)\n",
    "    output_list = torch.from_numpy(np.array(padded_output))\n",
    "    output_length = torch.LongTensor(output_lens)\n",
    "    \n",
    "    if CUDA:\n",
    "        input_list = input_list.cuda()\n",
    "        output_list = output_list.cuda()\n",
    "        input_length = input_length.cuda()\n",
    "        output_length = output_length.cuda()\n",
    "            \n",
    "    return [input_list, input_length, output_list, output_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "'''\n",
    "NMTDataset needs index pairs, need to call indexesFromPairs functions beforehand\n",
    "The dataLoader is sorted according to length of the input_length, and padded to\n",
    "max length of input and output list repectively\n",
    "TODO: output_list is not sorted, hence need to sort (maybe) in the rnn sequence.\n",
    "'''\n",
    "# train_zh_dataset = NMTDataset(zh_train_pairs_cleaned, input_zh, output_zh_en)\n",
    "# train_vi_dataset = NMTDataset(vi_train_pairs_cleaned, input_vi, output_vi_en)\n",
    "# val_zh_dataset = NMTDataset(zh_val_pairs_cleaned, input_zh, output_zh_en)\n",
    "# val_vi_dataset = NMTDataset(vi_val_pairs_cleaned, input_vi, output_vi_en)\n",
    "# test_zh_dataset = NMTDataset(zh_test_pairs_cleaned, input_zh, output_zh_en)\n",
    "# test_vi_dataset = NMTDataset(vi_test_pairs_cleaned, input_vi, output_vi_en)\n",
    "\n",
    "# train_zh_dataset = NMTDataset(zh_train_pairs_cleaned)\n",
    "train_vi_dataset = NMTDataset(vi_train_pairs_cleaned)\n",
    "# val_zh_dataset = NMTDataset(zh_val_pairs_cleaned)\n",
    "val_vi_dataset = NMTDataset(vi_val_pairs_cleaned)\n",
    "# test_zh_dataset = NMTDataset(zh_test_pairs_cleaned)\n",
    "test_vi_dataset = NMTDataset(vi_test_pairs_cleaned)\n",
    "\n",
    "\n",
    "# train_zh_loader = torch.utils.data.DataLoader(dataset = train_zh_dataset, \n",
    "#                                           batch_size = BATCH_SIZE,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = True)\n",
    "\n",
    "train_vi_loader = torch.utils.data.DataLoader(dataset = train_vi_dataset, \n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = True)\n",
    "\n",
    "#Will use batch size 1 for validation and test since the sentence will be translated one by one\n",
    "# val_zh_loader = torch.utils.data.DataLoader(dataset = val_zh_dataset, \n",
    "#                                           batch_size = 1,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = False)\n",
    "val_vi_loader = torch.utils.data.DataLoader(dataset = val_vi_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "# test_zh_loader = torch.utils.data.DataLoader(dataset = test_zh_dataset, \n",
    "#                                           batch_size = 1,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = False)\n",
    "test_vi_loader = torch.utils.data.DataLoader(dataset = test_vi_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "#Input_batch in size Batch x maxLen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (input_list, input_length, output_list, output_length) in enumerate(val_zh_loader):\n",
    "#     if i== 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_list.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here for the constant definition\n",
    "# MAX_SENTENCE_LENGTH = 10\n",
    "hidden_size = 256\n",
    "max_length = 10\n",
    "BATCH_SIZE = 3\n",
    "TEST_BATCH_SIZE = 3\n",
    "CLIP = 50\n",
    "TEACHER_RATIO = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# #loading data\n",
    "# # loaded_zh_embeddings = pkl.load(open(ftdir+'zh_embeddings.p', 'rb'))\n",
    "# loaded_vi_embeddings = pkl.load(open(ftdir+'vi_embeddings.p', 'rb'))\n",
    "# loaded_en_embeddings = pkl.load(open(ftdir+'en_embeddings.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA = False\n",
    "# loaded_zh_embeddings = torch.from_numpy(loaded_zh_embeddings).float()\n",
    "loaded_vi_embeddings = torch.from_numpy(loaded_vi_embeddings).float()\n",
    "loaded_en_embeddings = torch.from_numpy(loaded_en_embeddings).float()\n",
    "\n",
    "if CUDA:\n",
    "#     loaded_zh_embeddings = loaded_zh_embeddings.cuda()\n",
    "    loaded_vi_embeddings = loaded_vi_embeddings.cuda()\n",
    "    loaded_en_embeddings = loaded_en_embeddings.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_size=emb_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(loaded_vi_embeddings, freeze=True)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_list, hidden):\n",
    "        embedded = self.embedding(input_list)\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "#         output, hidden = self.gru(packed, hidden)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embed_size=emb_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(loaded_en_embeddings, freeze=True)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input)        \n",
    "        output = F.relu(output)        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "encoder_test = EncoderRNN(hidden_size).to(device)\n",
    "decoder_test = DecoderRNN(hidden_size, len(vi_ordered_words)).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i, (input_list,input_length,output_list, output_length) in enumerate(train_vi_loader):\n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "            \n",
    "    encoder_hidden = encoder_test.initHidden(batch_size)\n",
    "    encoder_output, encoder_hidden = encoder_test(input_list, encoder_hidden)\n",
    "#     encoder_output, encoder_hidden = batch_encoder(input_list, input_length, encoder_hidden)\n",
    "    \n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "#     decoder_input = torch.tensor([[SOS_TOKEN]]*batch_size, device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "#     decoder_hidden = encoder_hidden[:batch_decoder.n_layers]\n",
    "\n",
    "    loss = 0\n",
    "    for di in range(max_output_length):\n",
    "\n",
    "        decoder_output, decoder_hidden = decoder_test(\n",
    "            decoder_input, decoder_hidden)\n",
    "\n",
    "\n",
    "        loss += criterion(decoder_output, output_list[:,di])\n",
    "        decoder_input = output_list[:,di].unsqueeze(0) \n",
    "    loss.backward()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referenced from lab8 1nmt and modified \n",
    "teacher_forcing_ratio = 0.5\n",
    "def batch_train(input_list, input_length, output_list,output_length, \n",
    "                batch_encoder, batch_decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    '''\n",
    "    param: @attention is a Boolean variable indicating whether using attention\n",
    "    '''\n",
    "    batch_encoder.train()\n",
    "    batch_decoder.train()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "    \n",
    "#     batch_size = input_list.size(0)\n",
    "    \n",
    "#     loss = 0\n",
    "    \n",
    "    encoder_hidden = batch_encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_outputs, encoder_hidden = batch_encoder(input_list, encoder_hidden)\n",
    "\n",
    "    #Initialize for decoding process\n",
    "    curr_batch = input_list.size(0)#Take the current batch size\n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "    \n",
    "#     decoder_hidden = encoder_hidden[:batch_decoder.n_layers]#Bidirectional summoned\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden = batch_decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            decoder_input = output_list[:,di].unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "\n",
    "    else:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden = batch_decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "            \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "learning_rate = 0.01\n",
    "\n",
    "encoder = EncoderRNN(hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, len(vi_ordered_words)).to(device)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i, (input_list,input_length,output_list, output_length) in enumerate(train_vi_loader):\n",
    "    loss = batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference lab8 1-nmt\n",
    "def greedy_evaluate(val_loader, encoder, decoder, en_id2words ):\n",
    "    #Will generate sentences 1 by 1. \n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    decoded_words_all = []\n",
    "              \n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for i, (input_list, input_length, output_list, output_length) in enumerate(val_loader):\n",
    "            if i %100 == 0:\n",
    "                print(\"%d/%d\"%(i,len(val_loader)))\n",
    "                \n",
    "            batch_size, max_input_length = input_list.size()\n",
    "            max_output_length = output_list.size(1)\n",
    "            \n",
    "            #    break\n",
    "            #batch_size, max_len = output_list.size()\n",
    "#             print(input_list.size())\n",
    "\n",
    "#         encoder_hidden = batch_encoder.initHidden(batch_size)\n",
    "\n",
    "#     encoder_outputs, encoder_hidden = batch_encoder(input_list, encoder_hidden)\n",
    "\n",
    "#     #Initialize for decoding process\n",
    "#     curr_batch = input_list.size(0)#Take the current batch size\n",
    "#     decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "    \n",
    "# #     decoder_hidden = encoder_hidden[:batch_decoder.n_layers]#Bidirectional summoned\n",
    "#     decoder_hidden = encoder_hidden\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_outputs, encoder_hidden = encoder(input_list, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size).reshape(1, batch_size), device=device)\n",
    "#             decoder_input = torch.tensor([[SOS_TOKEN]], device=device)  # SOS\n",
    "            # decode the context vector\n",
    "            decoder_hidden = encoder_hidden\n",
    "#             decoder_hidden = encoder_hidden[:decoder.n_layers] # decoder starts from the last encoding sentence\n",
    "            # output of this function\n",
    "            decoded_words = []\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input.reshape(1, batch_size), decoder_hidden)\n",
    "\n",
    "                top_score, topi = decoder_output.data.topk(1)\n",
    "                decoded_words.append(en_id2words[topi.item()])\n",
    "                if topi.item() == EOS_TOKEN:\n",
    "                    break\n",
    "                else:\n",
    "                    decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "                    \n",
    "            decoded_words_all.append(decoded_words)\n",
    "\n",
    "        return decoded_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_words_all, decoder_attention_all = greedy_attn_evaluate(val_zh_loader, pre_encoder, attn_decoder, en_id2words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(decoded_words_all):\n",
    "    cleaned_decoded_words_all = []\n",
    "    \n",
    "    for sentence in decoded_words_all:\n",
    "        cleaned_sentence = []\n",
    "        for word in sentence:\n",
    "            if word == '<PAD>':\n",
    "                continue\n",
    "            else:\n",
    "                cleaned_sentence.append(word)\n",
    "        if cleaned_sentence[-1] != '<EOS>':\n",
    "            cleaned_sentence.append(' <EOS>')\n",
    "            \n",
    "        cleaned_decoded_words_all.append(cleaned_sentence)\n",
    "        \n",
    "    return cleaned_decoded_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translate the test and val lists back to english\n",
    "def en_translate(index_list, en_id2words):\n",
    "    translated_sentence_list = []\n",
    "    for sentence in index_list:\n",
    "        translated_sentence = []\n",
    "        for index in sentence:\n",
    "            translated_sentence.append(en_id2words[index])\n",
    "        #translated_sentence.append('<EOS>')\n",
    "        translated_sentence_list.append(translated_sentence)\n",
    "    return translated_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_words_list = post_process(decoded_words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_words_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when',\n",
       " 'i',\n",
       " 'was',\n",
       " 'little',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'my',\n",
       " 'country',\n",
       " 'was',\n",
       " 'the',\n",
       " 'best',\n",
       " 'on',\n",
       " 'the',\n",
       " 'planet',\n",
       " 'and',\n",
       " 'i',\n",
       " 'grew',\n",
       " 'up',\n",
       " 'singing',\n",
       " 'a',\n",
       " 'song',\n",
       " 'called',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'envy',\n",
       " '.',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_en_val_list = [pair[1] for pair in vi_val_pairs_cleaned]\n",
    "translated_sentence_list = en_translate(vi_en_val_list, en_id2words)\n",
    "translated_sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference LAB8 1-nmt\n",
    "model_path = './model/'\n",
    "def TrainIters(train_loader, val_loader, encoder, decoder, n_iters, val_translated_list,\n",
    "                   print_every=100, plot_every=100, eval_every=500, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    epoch = 0\n",
    "    epoch_total = n_iters*len(train_loader)\n",
    "    \n",
    "    for iter in range(n_iters):\n",
    "        #print(\"Epoch {}/{}\".format(i+1, n_epochs))\n",
    "        for i, (input_list,input_length,output_list, output_length) in enumerate(train_loader):\n",
    "            loss = batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "#             if i > 0 and i % eval_every == 0:\n",
    "#                 decoded_val, decoder_attentions = greedy_attn_evaluate(val_loader, encoder, decoder, en_id2words)\n",
    "#                 decoded_clean = post_process(decoded_val)\n",
    "#                 print('bleu score is {}'.format(raw_corpus_bleu(decoded_val, val_translated_list).score))\n",
    "\n",
    "            if i > 0 and i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / epoch_total),\n",
    "                                             epoch, epoch / epoch_total * 100, print_loss_avg))\n",
    "\n",
    "            if i > 0 and i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "            epoch += 1\n",
    "            \n",
    "        torch.save(encoder.state_dict(), model_path + \"encoder_rnn_atten_\"+str(start)+\".pth\")\n",
    "        torch.save(decoder.state_dict(), model_path + \"decoder_rnn_atten_\"+str(start)+\".pth\")\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 4s (- 132m 10s) (100 0%) 227.4435\n",
      "2m 7s (- 130m 10s) (200 1%) 140.7197\n",
      "3m 12s (- 129m 15s) (300 2%) 139.8227\n",
      "4m 15s (- 128m 0s) (400 3%) 131.1037\n",
      "5m 20s (- 127m 0s) (500 4%) 125.4665\n",
      "6m 23s (- 125m 52s) (600 4%) 121.2966\n",
      "7m 28s (- 124m 51s) (700 5%) 121.4772\n",
      "8m 31s (- 123m 45s) (800 6%) 117.7168\n",
      "9m 36s (- 122m 47s) (900 7%) 118.7726\n",
      "10m 39s (- 121m 37s) (1000 8%) 115.6104\n",
      "11m 43s (- 120m 31s) (1100 8%) 116.4160\n",
      "12m 47s (- 119m 26s) (1200 9%) 116.8777\n",
      "13m 51s (- 118m 22s) (1300 10%) 114.6413\n",
      "14m 55s (- 117m 17s) (1400 11%) 114.8306\n",
      "15m 59s (- 116m 15s) (1500 12%) 112.0793\n",
      "17m 3s (- 115m 8s) (1600 12%) 111.2863\n",
      "18m 7s (- 114m 7s) (1700 13%) 113.3604\n",
      "19m 11s (- 113m 3s) (1800 14%) 112.2191\n",
      "20m 15s (- 111m 59s) (1900 15%) 110.6186\n",
      "21m 19s (- 110m 55s) (2000 16%) 108.5051\n",
      "22m 23s (- 109m 51s) (2100 16%) 110.6886\n",
      "23m 27s (- 108m 47s) (2200 17%) 110.9590\n",
      "24m 31s (- 107m 43s) (2300 18%) 108.8445\n",
      "25m 35s (- 106m 39s) (2400 19%) 109.1945\n",
      "26m 39s (- 105m 35s) (2500 20%) 111.6060\n",
      "27m 43s (- 104m 33s) (2600 20%) 111.9144\n",
      "28m 47s (- 103m 28s) (2700 21%) 107.6388\n",
      "29m 51s (- 102m 26s) (2800 22%) 111.5954\n",
      "30m 55s (- 101m 22s) (2900 23%) 107.4035\n",
      "31m 59s (- 100m 17s) (3000 24%) 105.9440\n",
      "33m 3s (- 99m 13s) (3100 24%) 107.3513\n",
      "34m 7s (- 98m 9s) (3200 25%) 106.4414\n",
      "35m 11s (- 97m 5s) (3300 26%) 106.3694\n",
      "36m 15s (- 96m 2s) (3400 27%) 108.0904\n",
      "37m 19s (- 94m 58s) (3500 28%) 107.0792\n",
      "38m 23s (- 93m 54s) (3600 29%) 103.8014\n",
      "39m 27s (- 92m 49s) (3700 29%) 104.2109\n",
      "40m 30s (- 91m 44s) (3800 30%) 104.3060\n",
      "41m 35s (- 90m 41s) (3900 31%) 106.3933\n",
      "42m 39s (- 89m 38s) (4000 32%) 106.4741\n",
      "43m 43s (- 88m 33s) (4100 33%) 102.2804\n",
      "45m 10s (- 87m 8s) (4235 34%) 137.8626\n",
      "46m 13s (- 86m 3s) (4335 34%) 102.5837\n",
      "47m 17s (- 84m 59s) (4435 35%) 102.6348\n",
      "48m 21s (- 83m 55s) (4535 36%) 106.7117\n",
      "49m 25s (- 82m 51s) (4635 37%) 102.8671\n",
      "50m 29s (- 81m 47s) (4735 38%) 103.5127\n",
      "51m 33s (- 80m 43s) (4835 38%) 100.4302\n",
      "52m 37s (- 79m 39s) (4935 39%) 103.1663\n",
      "53m 40s (- 78m 34s) (5035 40%) 98.7597\n",
      "54m 44s (- 77m 30s) (5135 41%) 100.6363\n",
      "55m 48s (- 76m 26s) (5235 42%) 101.9165\n",
      "56m 52s (- 75m 21s) (5335 43%) 100.3294\n",
      "57m 56s (- 74m 17s) (5435 43%) 102.1684\n",
      "58m 59s (- 73m 12s) (5535 44%) 98.4238\n",
      "60m 3s (- 72m 9s) (5635 45%) 100.4659\n",
      "61m 7s (- 71m 5s) (5735 46%) 103.5944\n",
      "62m 11s (- 70m 1s) (5835 47%) 99.6775\n",
      "63m 15s (- 68m 57s) (5935 47%) 103.3461\n",
      "64m 19s (- 67m 53s) (6035 48%) 100.7750\n",
      "65m 23s (- 66m 49s) (6135 49%) 98.7374\n",
      "66m 26s (- 65m 44s) (6235 50%) 97.9106\n",
      "67m 29s (- 64m 40s) (6335 51%) 99.1179\n",
      "68m 33s (- 63m 36s) (6435 51%) 99.7907\n",
      "69m 37s (- 62m 32s) (6535 52%) 100.0139\n",
      "70m 41s (- 61m 28s) (6635 53%) 99.5744\n",
      "71m 45s (- 60m 24s) (6735 54%) 102.6720\n",
      "72m 49s (- 59m 20s) (6835 55%) 103.3579\n",
      "73m 53s (- 58m 16s) (6935 55%) 100.0395\n",
      "74m 57s (- 57m 12s) (7035 56%) 101.7014\n",
      "76m 1s (- 56m 9s) (7135 57%) 99.9647\n",
      "77m 5s (- 55m 5s) (7235 58%) 97.5735\n",
      "78m 9s (- 54m 1s) (7335 59%) 98.2706\n",
      "79m 13s (- 52m 57s) (7435 59%) 98.2948\n",
      "80m 16s (- 51m 53s) (7535 60%) 97.8129\n",
      "81m 20s (- 50m 49s) (7635 61%) 99.5074\n",
      "82m 24s (- 49m 45s) (7735 62%) 99.0774\n",
      "83m 28s (- 48m 41s) (7835 63%) 98.9669\n",
      "84m 32s (- 47m 37s) (7935 63%) 100.6763\n",
      "85m 35s (- 46m 33s) (8035 64%) 97.3090\n",
      "86m 39s (- 45m 29s) (8135 65%) 98.4624\n",
      "87m 43s (- 44m 25s) (8235 66%) 100.2315\n",
      "89m 10s (- 42m 59s) (8370 67%) 132.4257\n",
      "90m 14s (- 41m 55s) (8470 68%) 97.5788\n",
      "91m 18s (- 40m 51s) (8570 69%) 95.2438\n",
      "92m 22s (- 39m 47s) (8670 69%) 96.5171\n",
      "93m 25s (- 38m 43s) (8770 70%) 96.3838\n",
      "94m 29s (- 37m 39s) (8870 71%) 97.0188\n",
      "95m 33s (- 36m 35s) (8970 72%) 100.8344\n",
      "96m 37s (- 35m 31s) (9070 73%) 96.7806\n",
      "97m 41s (- 34m 27s) (9170 73%) 99.8794\n",
      "98m 45s (- 33m 23s) (9270 74%) 97.7477\n",
      "99m 49s (- 32m 19s) (9370 75%) 96.3501\n",
      "100m 52s (- 31m 15s) (9470 76%) 94.2273\n",
      "101m 56s (- 30m 11s) (9570 77%) 92.6102\n",
      "102m 59s (- 29m 7s) (9670 77%) 95.5818\n",
      "104m 3s (- 28m 3s) (9770 78%) 96.1896\n",
      "105m 7s (- 26m 59s) (9870 79%) 94.4197\n",
      "106m 11s (- 25m 56s) (9970 80%) 99.7519\n",
      "107m 16s (- 24m 52s) (10070 81%) 96.5292\n",
      "108m 19s (- 23m 48s) (10170 81%) 94.6565\n",
      "109m 24s (- 22m 44s) (10270 82%) 97.6422\n",
      "110m 28s (- 21m 40s) (10370 83%) 96.4368\n",
      "111m 32s (- 20m 36s) (10470 84%) 96.5694\n",
      "112m 35s (- 19m 32s) (10570 85%) 92.9281\n",
      "113m 39s (- 18m 28s) (10670 86%) 96.8145\n",
      "114m 44s (- 17m 25s) (10770 86%) 98.7963\n",
      "115m 47s (- 16m 21s) (10870 87%) 96.1463\n",
      "116m 51s (- 15m 17s) (10970 88%) 94.2745\n",
      "117m 55s (- 14m 13s) (11070 89%) 95.0620\n",
      "118m 59s (- 13m 9s) (11170 90%) 96.9396\n",
      "120m 3s (- 12m 5s) (11270 90%) 94.9578\n",
      "121m 7s (- 11m 1s) (11370 91%) 93.6581\n",
      "122m 11s (- 9m 57s) (11470 92%) 95.6606\n",
      "123m 15s (- 8m 53s) (11570 93%) 98.7074\n",
      "124m 19s (- 7m 49s) (11670 94%) 97.1803\n",
      "125m 23s (- 6m 45s) (11770 94%) 98.8897\n",
      "126m 27s (- 5m 41s) (11870 95%) 94.9945\n",
      "127m 31s (- 4m 38s) (11970 96%) 95.8959\n",
      "128m 35s (- 3m 34s) (12070 97%) 98.5974\n",
      "129m 38s (- 2m 30s) (12170 98%) 94.9870\n",
      "130m 42s (- 1m 26s) (12270 98%) 95.7041\n",
      "131m 46s (- 0m 22s) (12370 99%) 94.7736\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'showPlot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-19c1d291c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m plot_losses = TrainIters(train_vi_loader, val_vi_loader, encoder, decoder, 3,\n\u001b[0;32m---> 10\u001b[0;31m                None, print_every=100, learning_rate=learning_rate)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-e3e2bc25d729>\u001b[0m in \u001b[0;36mTrainIters\u001b[0;34m(train_loader, val_loader, encoder, decoder, n_iters, val_translated_list, print_every, plot_every, eval_every, learning_rate)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"decoder_rnn_atten_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mshowPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'showPlot' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_size = 300\n",
    "\n",
    "encoder = EncoderRNN(hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, len(vi_ordered_words)).to(device)\n",
    "# pre_encoder = PreBatchEncoderRNN(loaded_vi_embeddings, emb_size, hidden_size, train_vi_loader.batch_size).to(device)\n",
    "# attn_decoder = PreAttnDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), train_vi_loader.batch_size).to(device)\n",
    "\n",
    "plot_losses = TrainIters(train_vi_loader, val_vi_loader, encoder, decoder, 3,\n",
    "               None, print_every=100, learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1262\n",
      "100/1262\n",
      "200/1262\n",
      "300/1262\n",
      "400/1262\n",
      "500/1262\n",
      "600/1262\n",
      "700/1262\n",
      "800/1262\n",
      "900/1262\n",
      "1000/1262\n",
      "1100/1262\n",
      "1200/1262\n"
     ]
    }
   ],
   "source": [
    "decoded_val = greedy_evaluate(val_vi_loader, encoder, decoder, en_id2words)\n",
    "decoded_clean = post_process(decoded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_bleu,raw_corpus_bleu\n",
    "\n",
    "def bleu_score(predicted_list,translated_list):\n",
    "    predicted_list_nopad = []\n",
    "    for ii in range(len(predicted_list)):\n",
    "        line = ''\n",
    "        for jj in predicted_list[ii]:\n",
    "            if jj != '<pad>':\n",
    "                line = line + ' ' + jj\n",
    "        predicted_list_nopad.append(line)\n",
    "    labels = []\n",
    "    for ii in range(len(translated_list)):\n",
    "        line = ''\n",
    "        for jj in translated_list[ii]:\n",
    "            if jj != '<pad>':\n",
    "                line = line + ' ' + jj\n",
    "        labels.append(line)\n",
    "    #print(len(labels))\n",
    "    #print(len(predicted_list_nopad))\n",
    "    print('bleu score for test dataset:', corpus_bleu(predicted_list_nopad, [labels]).score)\n",
    "    print('bleu score for test dataset [raw]:', raw_corpus_bleu(predicted_list_nopad, [labels]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for test dataset: 12.271951797052619\n",
      "bleu score for test dataset [raw]: 2.8268412008977353\n"
     ]
    }
   ],
   "source": [
    "bleu_score(decoded_clean,translated_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for test dataset: 13.244067757436477\n",
      "bleu score for test dataset [raw]: 3.1149446308128703\n"
     ]
    }
   ],
   "source": [
    "bleu_score(decoded_clean,translated_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so', 'there', 's', 'this', '.', 'this', '.', '.', '<EOS>']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(decoded_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = timer()\n",
    "i = 0\n",
    "for batch in train_zh_loader:\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-80f084b89653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshowPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_losses' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
