{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "#from sacrebleu import raw_corpus_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define constants here\n",
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 5\n",
    "MAX_LENGTH = 80\n",
    "words_to_load = 50000\n",
    "emb_size = 300\n",
    "wiki_size = 300\n",
    "CUDA = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ht1162/anaconda3/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = os.getcwd() + '/'\n",
    "datadir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained word embeddings:\n",
    "Reference: https://fasttext.cc/docs/en/pretrained-vectors.html\n",
    "\n",
    "@article{bojanowski2017enriching,\n",
    "  title={Enriching Word Vectors with Subword Information},\n",
    "  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},\n",
    "  journal={Transactions of the Association for Computational Linguistics},\n",
    "  volume={5},\n",
    "  year={2017},\n",
    "  issn={2307-387X},\n",
    "  pages={135--146}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reference Lab4 HW2\n",
    "# datadir = os.getcwd()\n",
    "words_to_load = 50000\n",
    "with open(datadir + 'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_en_embeddings = np.zeros(((words_to_load+4), wiki_size))\n",
    "    en_word2id = {}\n",
    "    en_id2words = {}\n",
    "    \n",
    "    en_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    en_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    en_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    en_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    en_word2id['<PAD>'] = PAD_TOKEN\n",
    "    en_word2id['<SOS>'] = SOS_TOKEN\n",
    "    en_word2id['<EOS>'] = EOS_TOKEN\n",
    "    en_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    en_ordered_words= []\n",
    "    en_ordered_words.append('<PAD>')\n",
    "    en_ordered_words.append('<SOS>')\n",
    "    en_ordered_words.append('<EOS>')\n",
    "    en_ordered_words.append('<UNK>')\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load:\n",
    "            break\n",
    "        if i ==0:#Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        #print(len(s))\n",
    "        loaded_en_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        en_word2id[s[0]] = i+4 #for extra pad and unk eos and unk\n",
    "        en_id2words[i+4] = s[0]\n",
    "        en_ordered_words.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 0 has wrong dimension, hence skipped\n"
     ]
    }
   ],
   "source": [
    "#Reference Lab4 HW2\n",
    "#Over 200000 loaded words, 58 has wrong dimensions\n",
    "#Too slow, swtiched to 50000\n",
    "words_to_load = 50000\n",
    "# datadir = os.getcwd()\n",
    "with open(datadir + 'cc.zh.300.vec') as f:\n",
    "    loaded_zh_embeddings = np.zeros(((words_to_load+4),wiki_size))\n",
    "    zh_word2id = {}\n",
    "    zh_id2words = {}\n",
    "    \n",
    "    zh_id2words[PAD_TOKEN] = '<PAD>'\n",
    "    zh_id2words[SOS_TOKEN] = '<SOS>'\n",
    "    zh_id2words[EOS_TOKEN] = '<EOS>'\n",
    "    zh_id2words[UNK_TOKEN] = '<UNK>'\n",
    "    \n",
    "    zh_word2id['<PAD>'] = PAD_TOKEN\n",
    "    zh_word2id['<SOS>'] = SOS_TOKEN\n",
    "    zh_word2id['<EOS>'] = EOS_TOKEN\n",
    "    zh_word2id['<UNK>'] = UNK_TOKEN\n",
    "    \n",
    "    zh_ordered_words= []\n",
    "    zh_ordered_words.append('<PAD>')\n",
    "    zh_ordered_words.append('<SOS>')\n",
    "    zh_ordered_words.append('<EOS>')\n",
    "    zh_ordered_words.append('<UNK>')\n",
    "    wrong_dim = 0;\n",
    "    for i, line in enumerate(f):\n",
    "        #print(line)\n",
    "        if i >= words_to_load:\n",
    "            break;\n",
    "        if i == 0: #Ignore the first line\n",
    "            continue;\n",
    "        s = line.split()\n",
    "        if len(s) != 301:\n",
    "            wrong_dim += 1#Skip the wrong dimension one\n",
    "            continue;\n",
    "        loaded_zh_embeddings[i+4,:] = np.asarray(s[1:])\n",
    "        zh_word2id[s[0]] = i+4 #for extra pad and unk \n",
    "        zh_id2words[i+4] = s[0]\n",
    "        zh_ordered_words.append(s[0])\n",
    "    print('In total {} has wrong dimension, hence skipped'.format(wrong_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(loaded_zh_embeddings, open(datadir+'zh_embeddings.p', 'wb'))\n",
    "pkl.dump(loaded_en_embeddings, open(datadir+'en_embeddings.p', 'wb'))\n",
    "#pkl.dump(loaded_vi_embeddings, open(datadir+'vi_embeddings.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name, emb_word2id, emb_id2word, emb_ordered_words):\n",
    "        self.name = name\n",
    "        self.word2index = emb_word2id\n",
    "        self.word2count = {}\n",
    "        self.index2word = emb_id2word #Dict\n",
    "        self.n_words = 4  # Count SOS and EOS +(batch: pad and unk)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count:\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "#Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s, lang):\n",
    "    if lang == \"en\":\n",
    "        s = s.replace(\"apos\", \"\").replace(\"quot\", \"\")\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #This line is commented out since it will not properly deal with Chinese Letters\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "#reference: LAB4 hw2\n",
    "def indexesFromSentences(lang1, lang2, pairs):\n",
    "    id_list1 = []\n",
    "    id_list2 = []\n",
    "    for i in range(len(pairs)):\n",
    "        sentence1 = pairs[i][0]\n",
    "        sentence2 = pairs[i][1]\n",
    "        \n",
    "        sentence1 = sentence1.replace('quot','')\n",
    "        sentence1 = sentence1.replace('apos', '')\n",
    "        sentence2 = sentence2.replace('quot','')\n",
    "        sentence2 = sentence2.replace('apos', '')\n",
    "        #If either sentence is empty, then remove the pair\n",
    "        if sentence1 == '' or sentence2 == '':\n",
    "            continue;\n",
    "        \n",
    "        id_sentence1 = [lang1.word2index[word] if word in lang1.word2index else UNK_TOKEN \n",
    "                        for word in sentence1.split()] + [EOS_TOKEN]\n",
    "        id_list1.append(id_sentence1)\n",
    "        id_sentence2 = [lang2.word2index[word] if word in lang2.word2index else UNK_TOKEN \n",
    "                        for word in sentence2.split()] + [EOS_TOKEN]\n",
    "        id_list2.append(id_sentence2)\n",
    "        \n",
    "   \n",
    "        \n",
    "    return id_list1,id_list2\n",
    "\n",
    "# def sentence2id(sentence_list):\n",
    "#     id_list = []\n",
    "#     for sentence in sentence_list:\n",
    "#         sentence_id_list = [word2id[word] if word in word2id else UNK_IDX for word in sentence]\n",
    "#         id_list.append(sentence_id_list)\n",
    "#     return id_list\n",
    "\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_TOKEN)\n",
    "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "#     return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "# def filterPair(p):\n",
    "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "#         len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "#         p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "# def filterPairs(pairs):\n",
    "#     return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, category, reverse = False):#category = ['train', 'dev','test]\n",
    "    print('Reading lines:')\n",
    "    lines1 = open(category +'.tok.'+ lang1.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data1 = [normalizeString(l, lang1.name) for l in lines1]\n",
    "    #data1 = list(filter(None, data1)) # fastest\n",
    "\n",
    "    lines2 = open(category + '.tok.' + lang2.name, encoding = 'utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "    data2 = [normalizeString(l, lang2.name) for l in lines2]\n",
    "    #Given that data2 is english hence we further normalize\n",
    "    data2 = [re.sub(r\"[^a-zA-Z.!?]+\", r\" \", data) for data in data2]\n",
    "    #data2 = list(filter(None, data2)) # fastest\n",
    "\n",
    "    return data1, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Preparation for CHN to ENG\n",
    "def prepareData(lang1, lang2, category, reverse = False):\n",
    "    data1, data2 = readLangs(lang1, lang2, category, reverse)#Read data returns list of sentences\n",
    "    pairs = [[data1[i], data2[i]] for i in range(len(data1))]\n",
    "    print('Read %s sentence pairs' % len(pairs))\n",
    "    #Count the words\n",
    "    print('Counting words')\n",
    "    for i in range(len(pairs)):\n",
    "        lang1.addSentence(data1[i])\n",
    "        lang2.addSentence(data2[i])\n",
    "\n",
    "    print('Counted Words')\n",
    "    print(lang1.name, lang1.n_words)\n",
    "    print(lang2.name, lang2.n_words)\n",
    "\n",
    "    return pairs, data1, data2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create language object\n",
    "input_zh = Lang('zh', zh_word2id, zh_id2words, zh_ordered_words)\n",
    "output_zh_en = Lang('en', en_word2id, en_id2words, en_ordered_words)\n",
    "# input_vi = Lang('vi', vi_word2id, vi_id2words, vi_ordered_words)\n",
    "# output_vi_en = Lang('en', en_word2id, en_id2words, en_ordered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines:\n",
      "Read 213376 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "zh 88426\n",
      "en 50958\n",
      "Reading lines:\n",
      "Read 1261 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "zh 88667\n",
      "en 51096\n",
      "Reading lines:\n",
      "Read 1397 sentence pairs\n",
      "Counting words\n",
      "Counted Words\n",
      "zh 88863\n",
      "en 51194\n"
     ]
    }
   ],
   "source": [
    "#Create the string pairs and the string lists\n",
    "train_zh_pairs, zh_train, zh_en_train = prepareData(input_zh, output_zh_en, 'train')\n",
    "val_zh_pairs, zh_val, zh_en_val = prepareData(input_zh, output_zh_en, 'dev')\n",
    "test_zh_pairs, zh_test, zh_en_test = prepareData(input_zh, output_zh_en, 'test')\n",
    "\n",
    "# train_vi_pairs, vi_train, vi_en_train = prepareData(input_vi, output_vi_en, 'train')\n",
    "# val_vi_pairs, vi_val, vi_en_val = prepareData(input_vi, output_vi_en, 'dev')\n",
    "# test_vi_pairs, vi_test, vi_en_test = prepareData(input_vi, output_vi_en, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在 恐惧 中 角色 就是 我们 自己', 'in our fears the characters are us .']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(train_zh_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zh_idx_train, zh_en_idx_train = indexesFromSentences(input_zh, output_zh_en, train_zh_pairs)\n",
    "zh_idx_val, zh_en_idx_val = indexesFromSentences(input_zh, output_zh_en, val_zh_pairs)\n",
    "zh_idx_test, zh_en_idx_test = indexesFromSentences(input_zh, output_zh_en, test_zh_pairs)\n",
    "\n",
    "# vi_idx_train, vi_en_idx_train = indexesFromSentences(input_vi, output_vi_en, train_vi_pairs)\n",
    "# vi_idx_val, vi_en_idx_val = indexesFromSentences(input_vi, output_vi_en, val_vi_pairs)\n",
    "# vi_idx_test, vi_en_idx_test = indexesFromSentences(input_vi, output_vi_en, test_vi_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zh_train_pairs = [[zh_idx_train[i], zh_en_idx_train[i]] for i in range(len(zh_idx_train))]\n",
    "zh_val_pairs = [[zh_idx_val[i], zh_en_idx_val[i]] for i in range(len(zh_idx_val))]\n",
    "zh_test_pairs= [[zh_idx_test[i], zh_en_idx_test[i]] for i in range(len(zh_idx_test))]\n",
    "# vi_train_pairs = [[vi_idx_train[i], vi_en_idx_train[i]] for i in range(len(vi_idx_train))]\n",
    "# vi_val_pairs = [[vi_idx_val[i], vi_en_idx_val[i]] for i in range(len(vi_idx_val))]\n",
    "# vi_test_pairs = [[vi_idx_test[i], vi_en_idx_test[i]] for i in range(len(vi_idx_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213376"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_zh_pairs)#Should be 213376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(zh_train_pairs, open('zh_train_pairs.p', 'wb'))\n",
    "pkl.dump(zh_val_pairs, open('zh_val_pairs.p', 'wb'))\n",
    "pkl.dump(zh_test_pairs, open('zh_test_pairs.p', 'wb'))\n",
    "\n",
    "# pkl.dump(vi_train_pairs, open('./data/vi_train_pairs.p', 'wb'))\n",
    "# pkl.dump(vi_val_pairs, open('./data/vi_val_pairs.p', 'wb'))\n",
    "# pkl.dump(vi_test_pairs, open('./data/vi_test_pairs.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531 502\n"
     ]
    }
   ],
   "source": [
    "max_train_len = 0\n",
    "second_len = 0\n",
    "for pair in zh_train_pairs:\n",
    "    if max_train_len < len(pair[0]):\n",
    "        second_len = max_train_len\n",
    "        max_train_len = len(pair[0])\n",
    "\n",
    "print(max_train_len, second_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For training data, we have max-len as 80: train: 132789/133316, val: 1267/1268, test: 1552/1553\n",
    "zh_train_pairs_cleaned= []\n",
    "zh_val_pairs_cleaned = []\n",
    "zh_test_pairs_cleaned = []\n",
    "MAX_LENGTH = 80\n",
    "for zh_list in zh_train_pairs:\n",
    "    if len(zh_list[0])<=MAX_LENGTH and len(zh_list[1]) <= MAX_LENGTH:\n",
    "        zh_train_pairs_cleaned.append(zh_list)\n",
    "        \n",
    "for zh_list in zh_val_pairs:\n",
    "    if len(zh_list[0])<=MAX_LENGTH and len(zh_list[1]) <= MAX_LENGTH:\n",
    "        zh_val_pairs_cleaned.append(zh_list)\n",
    "\n",
    "for zh_list in zh_test_pairs:\n",
    "    if len(zh_list[0])<=MAX_LENGTH and len(zh_list[1]) <= MAX_LENGTH:\n",
    "        zh_test_pairs_cleaned.append(zh_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212922, 211737)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zh_train_pairs),len(zh_train_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1261, 1257)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zh_val_pairs), len(zh_val_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1397, 1257)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zh_test_pairs),len(zh_val_pairs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "pkl.dump(zh_train_pairs_cleaned, open('zh_train_pairs_cleaned.p', 'wb'))\n",
    "pkl.dump(zh_val_pairs_cleaned, open('zh_val_pairs_cleaned.p', 'wb'))\n",
    "pkl.dump(zh_test_pairs_cleaned, open('zh_test_pairs_cleaned.p', 'wb'))\n",
    "\n",
    "# pkl.dump(vi_train_pairs_cleaned, open('./data/vi_train_pairs_cleaned.p', 'wb'))\n",
    "# pkl.dump(vi_val_pairs_cleaned, open('./data/vi_val_pairs_cleaned.p', 'wb'))\n",
    "# pkl.dump(vi_test_pairs_cleaned, open('./data/vi_test_pairs_cleaned.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# #loading data\n",
    "# # zh_train_pairs_cleaned = pkl.load(open('./data/zh_train_pairs_cleaned.p', 'rb'))\n",
    "# # zh_val_pairs_cleaned = pkl.load(open('./data/zh_val_pairs_cleaned.p', 'rb'))\n",
    "# # zh_test_pairs_cleaned = pkl.load(open('./data/zh_test_pairs_cleaned.p', 'rb'))\n",
    "\n",
    "# vi_train_pairs_cleaned = pkl.load(open('./data/vi_train_pairs_cleaned.p', 'rb'))\n",
    "# vi_val_pairs_cleaned = pkl.load(open('./data/vi_val_pairs_cleaned.p', 'rb'))\n",
    "# vi_test_pairs_cleaned = pkl.load(open('./data/vi_test_pairs_cleaned.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, pairs):#Needs the index pairs\n",
    "        self.pairs = pairs\n",
    "#         self.input_lang = input_lang\n",
    "#         self.output_lang = output_lang\n",
    "        self.input_seqs = [pairs[i][0] for i in range(len(self.pairs))]\n",
    "        self.output_seqs = [pairs[i][1] for i in range(len(self.pairs))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)#Returning number of pairs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_seq = self.input_seqs[index]\n",
    "        output_seq = self.output_seqs[index]\n",
    "        return [input_seq, len(input_seq), output_seq, len(output_seq)]\n",
    "    \n",
    "def vocab_collate_func(batch):\n",
    "    #Reference: lab8_3_mri\n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq) for seq in seqs]\n",
    "#         padded_seqs = torch.zeros(len(seqs), max(lens)).long()\n",
    "        padded_seqs = torch.zeros(len(seqs), MAX_LENGTH).long()\n",
    "        for i, seq in enumerate(seqs):\n",
    "            end = lens[i]\n",
    "            padded_seqs[i, :end] = torch.LongTensor(seq[:end])\n",
    "        return padded_seqs, lens\n",
    "    \n",
    "    batch_input_seqs = [datum[0] for datum in batch]\n",
    "    batch_output_seqs = [datum[2] for datum in batch]\n",
    "    #batch_input_length = [datum[1] for datum in batch]\n",
    "    #batch_output_length = [datum[3] for datum in batch]\n",
    "\n",
    "    sorted_pairs = sorted(zip(batch_input_seqs, batch_output_seqs), key=lambda x: len(x[0]), reverse = True)\n",
    "    in_seq_sorted, out_seq_sorted = zip(*sorted_pairs)\n",
    "    \n",
    "    padded_input,input_lens = _pad_sequences(in_seq_sorted)\n",
    "    padded_output,output_lens = _pad_sequences(out_seq_sorted)\n",
    "    \n",
    "    input_list = torch.from_numpy(np.array(padded_input))\n",
    "    input_length = torch.LongTensor(input_lens)\n",
    "    output_list = torch.from_numpy(np.array(padded_output))\n",
    "    output_length = torch.LongTensor(output_lens)\n",
    "    \n",
    "    if CUDA:\n",
    "        input_list = input_list.cuda()\n",
    "        output_list = output_list.cuda()\n",
    "        input_length = input_length.cuda()\n",
    "        output_length = output_length.cuda()\n",
    "            \n",
    "    return [input_list, input_length, output_list, output_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "'''\n",
    "NMTDataset needs index pairs, need to call indexesFromPairs functions beforehand\n",
    "The dataLoader is sorted according to length of the input_length, and padded to\n",
    "max length of input and output list repectively\n",
    "output_list is not sorted, hence need to sort (maybe) in the rnn sequence.\n",
    "'''\n",
    "# train_zh_dataset = NMTDataset(zh_train_pairs_cleaned, input_zh, output_zh_en)\n",
    "# train_vi_dataset = NMTDataset(vi_train_pairs_cleaned, input_vi, output_vi_en)\n",
    "# val_zh_dataset = NMTDataset(zh_val_pairs_cleaned, input_zh, output_zh_en)\n",
    "# val_vi_dataset = NMTDataset(vi_val_pairs_cleaned, input_vi, output_vi_en)\n",
    "# test_zh_dataset = NMTDataset(zh_test_pairs_cleaned, input_zh, output_zh_en)\n",
    "# test_vi_dataset = NMTDataset(vi_test_pairs_cleaned, input_vi, output_vi_en)\n",
    "\n",
    "train_zh_dataset = NMTDataset(zh_train_pairs_cleaned)\n",
    "#train_vi_dataset = NMTDataset(vi_train_pairs_cleaned)\n",
    "val_zh_dataset = NMTDataset(zh_val_pairs_cleaned)\n",
    "#val_vi_dataset = NMTDataset(vi_val_pairs_cleaned)\n",
    "test_zh_dataset = NMTDataset(zh_test_pairs_cleaned)\n",
    "#test_vi_dataset = NMTDataset(vi_test_pairs_cleaned)\n",
    "\n",
    "\n",
    "train_zh_loader = torch.utils.data.DataLoader(dataset = train_zh_dataset, \n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = True)\n",
    "\n",
    "# train_vi_loader = torch.utils.data.DataLoader(dataset = train_vi_dataset, \n",
    "#                                           batch_size = BATCH_SIZE,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = True)\n",
    "\n",
    "# #Will use batch size 1 for validation and test since the sentence will be translated one by one\n",
    "val_zh_loader = torch.utils.data.DataLoader(dataset = val_zh_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "# val_vi_loader = torch.utils.data.DataLoader(dataset = val_vi_dataset, \n",
    "#                                           batch_size = 1,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = False)\n",
    "test_zh_loader = torch.utils.data.DataLoader(dataset = test_zh_dataset, \n",
    "                                          batch_size = 1,\n",
    "                                          collate_fn = vocab_collate_func,\n",
    "                                          shuffle = False)\n",
    "# test_vi_loader = torch.utils.data.DataLoader(dataset = test_vi_dataset, \n",
    "#                                           batch_size = 1,\n",
    "#                                           collate_fn = vocab_collate_func,\n",
    "#                                           shuffle = False)\n",
    "#Input_batch in size Batch x maxLen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (input_list, input_length, output_list, output_length) in enumerate(train_zh_loader):\n",
    "    if i== 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here for the constant definition\n",
    "# MAX_SENTENCE_LENGTH = 10\n",
    "hidden_size = 256\n",
    "\n",
    "TEST_BATCH_SIZE = 3\n",
    "CLIP = 50\n",
    "TEACHER_RATIO = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "#loading data\n",
    "loaded_zh_embeddings = pkl.load(open(datadir+'zh_embeddings.p', 'rb'))\n",
    "#loaded_vi_embeddings = pkl.load(open(datadir+'vi_embeddings.p', 'rb'))\n",
    "loaded_en_embeddings = pkl.load(open(datadir+'en_embeddings.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loaded_zh_embeddings = torch.from_numpy(loaded_zh_embeddings).float()\n",
    "#loaded_vi_embeddings = torch.from_numpy(loaded_vi_embeddings).float()\n",
    "#loaded_en_embeddings = torch.from_numpy(loaded_en_embeddings).float()\n",
    "\n",
    "if CUDA:\n",
    "    loaded_zh_embeddings = loaded_zh_embeddings.cuda()\n",
    "    #loaded_vi_embeddings = loaded_vi_embeddings.cuda()\n",
    "    loaded_en_embeddings = loaded_en_embeddings.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reference Lab8 1-nmt\n",
    "class PreBatchEncoderRNN(nn.Module):\n",
    "    def __init__(self, emb, emb_size, hidden_size , n_layers = 1, dropout_p = 0.1):\n",
    "        super(PreBatchEncoderRNN, self).__init__()\n",
    "        #self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        #self.dropout = nn.Dropout(dropout_p)\n",
    "        self.embedding = nn.Embedding.from_pretrained(emb, True)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, bidirectional = True, batch_first = True)\n",
    "\n",
    "    def forward(self, input_list, input_length, hidden):\n",
    "        self.batch_size = input_list.size(0)\n",
    "        embedded = self.embedding(input_list)#Batch x seq x emb_size=300\n",
    "        #Input length sorted by loader\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_length,  batch_first = True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first = True, total_length = MAX_LENGTH)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        \n",
    "        #outputs B x L x H\n",
    "        #hidden size (2*n_layers) x B x H\n",
    "        return outputs, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(2*self.n_layers, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 80, 256]), torch.Size([2, 32, 256]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "hidden = encoder.initHidden(BATCH_SIZE)\n",
    "encoder_outputs, encoder_hidden = encoder(input_list, input_length, hidden)\n",
    "encoder_outputs.size(), encoder_hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "class PreBatchAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, emb, emb_size, hidden_size, output_size, n_layers = 1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(PreBatchAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        #self.attn = nn.Linear(hidden_size*2, hidden_size)\n",
    "        #self.attn2 = nn.Linear(hidden_size, hidden_size)\n",
    "        #self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        self.embedding = nn.Embedding.from_pretrained(self.emb, False)\n",
    "        self.attn = nn.Linear(emb_size + hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(emb_size + hidden_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, batch_first = False)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, decoder_input, hidden, encoder_outputs):\n",
    "        self.batch_size = encoder_outputs.size(0)\n",
    "        embedded = self.embedding(decoder_input).view(1, self.batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        concat_input = torch.cat((embedded, hidden), 2)\n",
    "        attn_weights = F.softmax(self.attn(concat_input), dim=2)\n",
    "        attn_energies = torch.bmm(attn_weights.squeeze(0).unsqueeze(1), encoder_outputs).squeeze(1)#Batch x H\n",
    "\n",
    "        output = torch.cat((embedded.squeeze(0), attn_energies), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        rnn_output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(rnn_output.squeeze(0)),dim=1)\n",
    "        #Size: output b x V, hidden 1 x b x h, attn 1 x b x max_length\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "#     def initHidden(self, batch_size):\n",
    "#         return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 50003]), torch.Size([1, 32, 256]), torch.Size([1, 32, 80]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = torch.tensor([SOS_TOKEN] * BATCH_SIZE).to(device)\n",
    "last_hidden = encoder_hidden[:1]\n",
    "test_decoder = PreBatchAttnDecoderRNN(loaded_zh_embeddings, emb_size,hidden_size, len(zh_ordered_words)).to(device)\n",
    "decoder_output, decoder_hidden, attn_weights = test_decoder(decoder_input, last_hidden, encoder_outputs)\n",
    "decoder_output.size(), decoder_hidden.size(), attn_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "test_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "test_decoder = PreBatchAttnDecoderRNN(loaded_zh_embeddings, emb_size,hidden_size, len(zh_ordered_words)).to(device)\n",
    "\n",
    "#decoder_test = AttnDecoderRNN(hidden_size, len(vi_ordered_words)).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i, (input_list,input_length,output_list, output_length) in enumerate(train_zh_loader):\n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "            \n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_outputs, encoder_hidden = test_encoder(input_list, input_length, encoder_hidden)\n",
    "#     encoder_output, encoder_hidden = batch_encoder(input_list, input_length, encoder_hidden)\n",
    "    \n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size), device=device)\n",
    "#     decoder_input = torch.tensor([[SOS_TOKEN]]*batch_size, device=device)\n",
    "    decoder_hidden = encoder_hidden[:test_decoder.n_layers]\n",
    "\n",
    "    loss = 0\n",
    "    for di in range(max_output_length):\n",
    "\n",
    "        decoder_output, decoder_hidden, decoder_attention = test_decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "\n",
    "        loss += criterion(decoder_output, output_list[:,di])\n",
    "        decoder_input = output_list[:,di].unsqueeze(0) \n",
    "    loss.backward()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Referenced from lab8 1nmt and modified \n",
    "teacher_forcing_ratio = 0.5\n",
    "def attn_batch_train(input_list, input_length, output_list,output_length, \n",
    "                batch_encoder, batch_decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    '''\n",
    "    param: @attention is a Boolean variable indicating whether using attention\n",
    "    '''\n",
    "    batch_encoder.train()\n",
    "    batch_decoder.train()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    batch_size, max_input_length = input_list.size()\n",
    "    max_output_length = output_list.size(1)\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = batch_encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_outputs, encoder_hidden = batch_encoder(input_list, input_length, encoder_hidden)\n",
    "\n",
    "    #Initialize for decoding process\n",
    "    #curr_batch = input_list.size(0)#Take the current batch size\n",
    "    decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size), device=device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden[:batch_decoder.n_layers]#Bidirectional summoned\n",
    "    #decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = batch_decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = output_list[:,di].unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "\n",
    "    else:\n",
    "        for di in range(max_output_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = batch_decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().unsqueeze(0)\n",
    "            loss += criterion(decoder_output, output_list[:,di])\n",
    "            \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()/MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "\n",
    "encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "decoder = PreBatchAttnDecoderRNN(loaded_zh_embeddings, emb_size,hidden_size, len(zh_ordered_words)).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i, (input_list,input_length,output_list, output_length) in enumerate(train_zh_loader):\n",
    "    loss = attn_batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.804374694824219"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Referenced from lab8 1nmt and modified \n",
    "# teacher_forcing_ratio = 0.5\n",
    "# def attn_batch_train(input_list, input_length, output_list,output_length, \n",
    "#                 batch_encoder, batch_decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "#     '''\n",
    "#     param: @attention is a Boolean variable indicating whether using attention\n",
    "#     '''\n",
    "#     batch_encoder.train()\n",
    "#     batch_decoder.train()\n",
    "    \n",
    "#     encoder_optimizer.zero_grad()\n",
    "#     decoder_optimizer.zero_grad()\n",
    "#     max_output_length = output_length.max().item()\n",
    "    \n",
    "#     batch_size = input_list.size(0)\n",
    "    \n",
    "#     loss = 0\n",
    "    \n",
    "#     encoder_hidden = batch_encoder.initHidden(batch_size)\n",
    "\n",
    "#     encoder_outputs, encoder_hidden = batch_encoder(input_list, input_length, encoder_hidden)\n",
    "\n",
    "#     #Initialize for decoding process\n",
    "#     curr_batch = input_list.size(0)#Take the current batch size\n",
    "#     decoder_input = torch.tensor([[SOS_TOKEN]]*curr_batch, device=device)\n",
    "    \n",
    "#     decoder_hidden = encoder_hidden[:batch_decoder.n_layers]#Bidirectional summoned\n",
    "# #     decoder_outputs = torch.zeros(max_output_length, curr_batch, batch_decoder.output_size)\n",
    "    \n",
    "#     # Move new Variables to CUDA\n",
    "#     if CUDA:\n",
    "#         decoder_input = decoder_input.cuda()\n",
    "# #         decoder_outputs = decoder_outputs.cuda()\n",
    "    \n",
    "#     use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "# #     use_teacher_forcing = True\n",
    "    \n",
    "#     if use_teacher_forcing:\n",
    "#     # Teacher forcing: Feed the target as the next input\n",
    "#         for di in range(max_output_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = batch_decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "# #             decoder_outputs[di] = decoder_output\n",
    "#             decoder_input = output_list[:,di] # Teacher forcing\n",
    "#             loss += criterion(decoder_output, output_list[:,di])\n",
    "\n",
    "#     else:\n",
    "#     # Without teacher forcing: use its own predictions as the next input\n",
    "#         for di in range(max_output_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = batch_decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "# #             decoder_outputs[di] = decoder_input\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach()# detach from history as input: size batch x 1 \n",
    "#             loss += criterion(decoder_output, output_list[:,di])\n",
    "            \n",
    "# #     loss += rnn_mask_loss(decoder_outputs.transpose(0,1).contiguous(), output_list.contiguous(), output_length)\n",
    "            \n",
    "#     loss.backward()\n",
    "#     ec = torch.nn.utils.clip_grad_norm(batch_encoder.parameters(), CLIP)\n",
    "#     dc = torch.nn.utils.clip_grad_norm(batch_decoder.parameters(), CLIP)\n",
    "\n",
    "#     encoder_optimizer.step()\n",
    "#     decoder_optimizer.step()\n",
    "\n",
    "#     return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning_rate = 0.01\n",
    "# encoder_optimizer = optim.SGD(pre_encoder.parameters(), lr=learning_rate)\n",
    "# decoder_optimizer = optim.SGD(pre_decoder.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# pre_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size, BATCH_SIZE)\n",
    "# pre_decoder = PreDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), BATCH_SIZE)\n",
    "# encoder_outputs, encoder_hidden = pre_encoder(input_list, input_length)\n",
    "# decoder_input = torch.tensor([[SOS_TOKEN]]*BATCH_SIZE)\n",
    "# decoder_hidden = encoder_hidden[:no_attn_decoder.n_layers]\n",
    "# max_output_length = output_length.max().item()\n",
    "# decoder_outputs = torch.zeros(max_output_length, curr_batch, pre_decoder.output_size)\n",
    "# loss = 0\n",
    "# for di in range(max_output_length):\n",
    "#     #print(di)\n",
    "#     decoder_output, decoder_hidden = pre_decoder(\n",
    "#         decoder_input, decoder_hidden)\n",
    "#     decoder_outputs[di] = decoder_output\n",
    "#     decoder_input = output_list[:,di] # Teacher forcing\n",
    "#     loss += criterion(decoder_output, output_list[:,di])\n",
    "# print(loss.item()/max_output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size, BATCH_SIZE).to(device)\n",
    "# attn_decoder = PreAttnDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), BATCH_SIZE)\n",
    "\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# encoder_optimizer = optim.SGD(pre_encoder.parameters(), lr=learning_rate)\n",
    "# decoder_optimizer = optim.SGD(attn_decoder.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# encoder_outputs, encoder_hidden = pre_encoder(input_list, input_length)\n",
    "# decoder_input = torch.tensor([[SOS_TOKEN]]*BATCH_SIZE)\n",
    "# decoder_hidden = encoder_hidden[:attn_decoder.n_layers]\n",
    "# max_output_length = output_length.max().item()\n",
    "# decoder_outputs = torch.zeros(max_output_length, curr_batch, attn_decoder.output_size)\n",
    "# loss = 0\n",
    "# for di in range(max_output_length):\n",
    "#     #print(di)\n",
    "#     decoder_output, decoder_hidden, attn_weights = attn_decoder(\n",
    "#         decoder_input, decoder_hidden, encoder_outputs)\n",
    "#     decoder_outputs[di] = decoder_output\n",
    "#     decoder_input = output_list[:,di] # Teacher forcing\n",
    "#     loss += criterion(decoder_output, output_list[:,di])\n",
    "# print(loss.item()/max_output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size, BATCH_SIZE).to(device)\n",
    "# pre_decoder = PreDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), BATCH_SIZE)\n",
    "\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# encoder_optimizer = optim.SGD(pre_encoder.parameters(), lr=learning_rate)\n",
    "# decoder_optimizer = optim.SGD(pre_decoder.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss = no_attn_batch_train(input_list, input_length, output_list, output_length, \n",
    "#                        pre_encoder, pre_decoder, encoder_optimizer, decoder_optimizer, \n",
    "#                        criterion)\n",
    "\n",
    "# print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size, BATCH_SIZE).to(device)\n",
    "# attn_decoder = PreAttnDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), BATCH_SIZE)\n",
    "\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# encoder_optimizer = optim.SGD(pre_encoder.parameters(), lr=learning_rate)\n",
    "# decoder_optimizer = optim.SGD(attn_decoder.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss = attn_batch_train(input_list, input_length, output_list, output_length, \n",
    "#                        pre_encoder, attn_decoder, encoder_optimizer, decoder_optimizer, \n",
    "#                        criterion)\n",
    "\n",
    "# print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size, BATCH_SIZE).to(device)\n",
    "# pre_decoder = PreDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), BATCH_SIZE).to(device)\n",
    "\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# encoder_optimizer = optim.SGD(pre_encoder.parameters(), lr=learning_rate)\n",
    "# decoder_optimizer = optim.SGD(pre_decoder.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train_loss = []\n",
    "# for i in range(2000):\n",
    "#     loss = no_attn_batch_train(input_list, input_length, output_list, output_length, \n",
    "#                        pre_encoder, pre_decoder, encoder_optimizer, decoder_optimizer, \n",
    "#                        criterion)\n",
    "#     train_loss.append(loss)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (12,10))\n",
    "# ax.plot(train_loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size, BATCH_SIZE).to(device)\n",
    "# attn_decoder = PreAttnDecoderRNN(loaded_en_embeddings, emb_size, hidden_size, len(en_ordered_words), BATCH_SIZE).to(device)\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# encoder_optimizer = optim.Adam(pre_encoder.parameters(), lr=learning_rate)\n",
    "# decoder_optimizer = optim.Adam(attn_decoder.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train_loss = []\n",
    "# for i in range(2000):\n",
    "#     loss = attn_batch_train(input_list, input_length, output_list, output_length, \n",
    "#                        pre_encoder, attn_decoder, encoder_optimizer, decoder_optimizer, \n",
    "#                        criterion)\n",
    "#     train_loss.append(loss)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (12,10))\n",
    "# ax.plot(train_loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attn_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference lab8 1-nmt\n",
    "def greedy_attn_evaluate(val_loader, encoder, decoder, en_id2words ):\n",
    "    #Will generate sentences 1 by 1. \n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    decoded_words_all = []\n",
    "    decoder_attentions_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for i, (input_list, input_length, output_list, output_length) in enumerate(val_loader):\n",
    "            if i %100 == 0:\n",
    "                print(\"%d/%d\"%(i,len(val_loader)))\n",
    "                \n",
    "            batch_size, max_input_length = input_list.size()\n",
    "            max_output_length = output_list.size(1)\n",
    "            \n",
    "            #    break\n",
    "            #batch_size, max_len = output_list.size()\n",
    "#             print(input_list.size())\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden(batch_size)\n",
    "            encoder_outputs, encoder_hidden = encoder(input_list, input_length, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor(np.array([[SOS_TOKEN]] * batch_size), device=device)#SOS\n",
    "            # decode the context vector\n",
    "            decoder_hidden = encoder_hidden[:decoder.n_layers] # decoder starts from the last encoding sentence\n",
    "            # output of this function\n",
    "            \n",
    "            decoded_words = []\n",
    "            decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "                top_score, topi = decoder_output.data.topk(1)\n",
    "                decoder_attentions[di, :decoder_attention.size(-1)] = decoder_attention\n",
    "                decoded_words.append(en_id2words[topi.item()])\n",
    "                if topi.item() == EOS_TOKEN:\n",
    "                    break\n",
    "                else:\n",
    "                    decoder_input = topi.squeeze().detach()\n",
    "                    \n",
    "            decoded_words_all.append(decoded_words)\n",
    "            decoder_attentions_all.append(decoder_attentions[:di+1])\n",
    "\n",
    "        return decoded_words_all, decoder_attentions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoded_words_all, decoder_attention_all = greedy_attn_evaluate(val_zh_loader, pre_encoder, attn_decoder, en_id2words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def post_process(decoded_words_all):\n",
    "    cleaned_decoded_words_all = []\n",
    "    \n",
    "    for sentence in decoded_words_all:\n",
    "        cleaned_sentence = []\n",
    "        for word in sentence:\n",
    "            if word == '<PAD>':\n",
    "                continue\n",
    "            else:\n",
    "                cleaned_sentence.append(word)\n",
    "        if cleaned_sentence[-1] != '<EOS>':\n",
    "            cleaned_sentence.append(' <EOS>')\n",
    "            \n",
    "        cleaned_decoded_words_all.append(cleaned_sentence)\n",
    "        \n",
    "    return cleaned_decoded_words_all\n",
    "\n",
    "#Translate the test and val lists back to english\n",
    "def en_translate(index_list, en_id2words):\n",
    "    translated_sentence_list = []\n",
    "    for sentence in index_list:\n",
    "        translated_sentence = []\n",
    "        for index in sentence:\n",
    "            translated_sentence.append(en_id2words[index])\n",
    "        #translated_sentence.append('<EOS>')\n",
    "        translated_sentence_list.append(translated_sentence)\n",
    "    return translated_sentence_list\n",
    "\n",
    "def zh_translate(index_list, zh_id2words):\n",
    "    translated_sentence_list = []\n",
    "    for sentence in index_list:\n",
    "        translated_sentence = []\n",
    "        for index in sentence:\n",
    "            translated_sentence.append(zh_id2words[index])\n",
    "        #translated_sentence.append('<EOS>')\n",
    "        translated_sentence_list.append(translated_sentence)\n",
    "    return translated_sentence_list\n",
    "\n",
    "def concatenate_tokens(token_lists):\n",
    "    sentence_list = []\n",
    "    for token_list in token_lists:\n",
    "        sentence = ''\n",
    "        for token in token_list:\n",
    "            sentence = sentence+' '+token\n",
    "        sentece_list.append(sentence)\n",
    "    return sentence_list\n",
    "        \n",
    "def bleu_score(pred_list, target_list):\n",
    "    pred_sentence_list = concatenate_tokens(pred_list)\n",
    "    target_sentence_list = concatenate_tokens(target_list)\n",
    "    print('bleu score for test dataset:', corpus_bleu(pred_sentence_list, [target_sentence_list]).score)\n",
    "    print('bleu score for test dataset [raw]:', raw_corpus_bleu(pred_sentence_list, [target_sentence_list]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoded_words_list = post_process(decoded_words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoded_words_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你好',\n",
       " '我',\n",
       " '是',\n",
       " '凯文',\n",
       " '<UNK>',\n",
       " '卡',\n",
       " '我',\n",
       " '是',\n",
       " 'youtube',\n",
       " '的',\n",
       " '趋势',\n",
       " '分析',\n",
       " '经理',\n",
       " '而',\n",
       " '我',\n",
       " '的',\n",
       " '专业',\n",
       " '就是',\n",
       " '观看',\n",
       " 'youtube',\n",
       " '视频',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_en_val_list = [pair[0] for pair in zh_val_pairs_cleaned]\n",
    "zh_translated_sentence_list = zh_translate(zh_en_val_list, zh_id2words)\n",
    "zh_translated_sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(zh_translated_sentence_list, open('zh_translated_sentence_list.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " '.',\n",
       " 'i',\n",
       " 'm',\n",
       " '<UNK>',\n",
       " '<UNK>',\n",
       " 'i',\n",
       " 'm',\n",
       " 'the',\n",
       " 'trends',\n",
       " 'manager',\n",
       " 'at',\n",
       " 'youtube',\n",
       " 'and',\n",
       " 'i',\n",
       " 'professionally',\n",
       " 'watch',\n",
       " 'youtube',\n",
       " 'videos',\n",
       " '.',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_en_val_list = [pair[1] for pair in zh_val_pairs_cleaned]\n",
    "translated_sentence_list = en_translate(zh_en_val_list, en_id2words)\n",
    "translated_sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl.dump(translated_sentence_list, open('translated_sentence_list_val.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), model_path + \"encoder_rnn_atten_\"+\".pth\")\n",
    "torch.save(decoder.state_dict(), model_path + \"decoder_rnn_atten_\"+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference LAB8 1-nmt\n",
    "model_path = datadir\n",
    "def AttnTrainIters(train_loader, val_loader, encoder, decoder, n_iters, val_translated_list,\n",
    "                   print_every=100, plot_every=100, eval_every=500, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    total_sample = 0\n",
    "    total_loss_list = []\n",
    "    for iter in range(n_iters):\n",
    "        losses = []\n",
    "        plot_loss_total = 0\n",
    "        print_loss_total = 0\n",
    "        for i, (input_list,input_length,output_list, output_length) in enumerate(train_loader):\n",
    "            loss = attn_batch_train(input_list, input_length, output_list, output_length, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            \n",
    "            total_loss_list.append(loss)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "#             if i > 0 and i % eval_every == 0:\n",
    "#                 decoded_val, decoder_attentions = greedy_attn_evaluate(val_loader, encoder, decoder, en_id2words)\n",
    "#                 decoded_clean = post_process(decoded_val)\n",
    "#                 print('bleu score is {}'.format(raw_corpus_bleu(decoded_val, val_translated_list).score))\n",
    "\n",
    "            if i > 0 and i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, total_sample / (n_iters*len(train_loader)) ),\n",
    "                                             total_sample, total_sample / (n_iters*len(train_loader)) * 100, print_loss_avg))\n",
    "\n",
    "            if i > 0 and i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "            total_sample += 1\n",
    "            \n",
    "        torch.save(encoder.state_dict(), model_path + \"encoder_rnn_attn2_\"+str(start)+\".pth\")\n",
    "        torch.save(decoder.state_dict(), model_path + \"decoder_rnn_attn2_\"+str(start)+\".pth\")\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return total_loss_list, plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 20s (- 87m 54s) (100 1%) 2.7042\n",
      "2m 40s (- 85m 44s) (200 3%) 1.6607\n",
      "3m 59s (- 84m 3s) (300 4%) 1.6244\n",
      "5m 19s (- 82m 41s) (400 6%) 1.6178\n",
      "6m 39s (- 81m 26s) (500 7%) 1.5573\n",
      "7m 59s (- 80m 9s) (600 9%) 1.5505\n",
      "9m 19s (- 78m 48s) (700 10%) 1.5148\n",
      "10m 39s (- 77m 32s) (800 12%) 1.5598\n",
      "11m 59s (- 76m 11s) (900 13%) 1.5805\n",
      "13m 19s (- 74m 52s) (1000 15%) 1.5276\n",
      "14m 40s (- 73m 33s) (1100 16%) 1.5397\n",
      "15m 59s (- 72m 11s) (1200 18%) 1.5269\n",
      "17m 19s (- 70m 52s) (1300 19%) 1.5424\n",
      "18m 39s (- 69m 30s) (1400 21%) 1.4902\n",
      "19m 59s (- 68m 11s) (1500 22%) 1.5022\n",
      "21m 18s (- 66m 49s) (1600 24%) 1.4572\n",
      "22m 38s (- 65m 30s) (1700 25%) 1.4941\n",
      "23m 58s (- 64m 9s) (1800 27%) 1.4526\n",
      "25m 18s (- 62m 49s) (1900 28%) 1.4657\n",
      "26m 38s (- 61m 29s) (2000 30%) 1.4198\n",
      "27m 58s (- 60m 10s) (2100 31%) 1.4385\n",
      "29m 18s (- 58m 51s) (2200 33%) 1.4285\n",
      "30m 38s (- 57m 31s) (2300 34%) 1.3837\n",
      "31m 58s (- 56m 11s) (2400 36%) 1.3921\n",
      "33m 18s (- 54m 51s) (2500 37%) 1.4192\n",
      "34m 38s (- 53m 31s) (2600 39%) 1.3971\n",
      "35m 58s (- 52m 11s) (2700 40%) 1.3853\n",
      "37m 18s (- 50m 51s) (2800 42%) 1.4187\n",
      "38m 38s (- 49m 31s) (2900 43%) 1.3849\n",
      "39m 58s (- 48m 11s) (3000 45%) 1.3703\n",
      "41m 18s (- 46m 51s) (3100 46%) 1.3861\n",
      "42m 38s (- 45m 31s) (3200 48%) 1.3661\n",
      "43m 58s (- 44m 11s) (3300 49%) 1.3491\n",
      "45m 18s (- 42m 52s) (3400 51%) 1.3720\n",
      "46m 38s (- 41m 32s) (3500 52%) 1.3361\n",
      "47m 58s (- 40m 12s) (3600 54%) 1.3328\n",
      "49m 18s (- 38m 52s) (3700 55%) 1.3426\n",
      "50m 38s (- 37m 32s) (3800 57%) 1.3638\n",
      "51m 58s (- 36m 12s) (3900 58%) 1.3787\n",
      "53m 18s (- 34m 52s) (4000 60%) 1.3442\n",
      "54m 38s (- 33m 32s) (4100 61%) 1.3296\n",
      "55m 58s (- 32m 12s) (4200 63%) 1.3158\n",
      "57m 18s (- 30m 52s) (4300 64%) 1.2941\n",
      "58m 38s (- 29m 32s) (4400 66%) 1.3116\n",
      "59m 58s (- 28m 12s) (4500 68%) 1.3646\n",
      "61m 18s (- 26m 53s) (4600 69%) 1.3528\n",
      "62m 39s (- 25m 33s) (4700 71%) 1.2976\n",
      "63m 59s (- 24m 13s) (4800 72%) 1.3586\n",
      "65m 19s (- 22m 53s) (4900 74%) 1.2964\n",
      "66m 39s (- 21m 33s) (5000 75%) 1.2890\n",
      "67m 58s (- 20m 13s) (5100 77%) 1.2976\n",
      "69m 18s (- 18m 53s) (5200 78%) 1.3032\n",
      "70m 38s (- 17m 33s) (5300 80%) 1.2922\n",
      "71m 58s (- 16m 13s) (5400 81%) 1.2989\n",
      "73m 18s (- 14m 53s) (5500 83%) 1.3013\n",
      "74m 37s (- 13m 33s) (5600 84%) 1.2919\n",
      "75m 57s (- 12m 13s) (5700 86%) 1.2793\n",
      "77m 17s (- 10m 53s) (5800 87%) 1.2704\n",
      "78m 37s (- 9m 33s) (5900 89%) 1.2834\n",
      "79m 57s (- 8m 13s) (6000 90%) 1.2877\n",
      "81m 18s (- 6m 53s) (6100 92%) 1.2961\n",
      "82m 38s (- 5m 33s) (6200 93%) 1.2733\n",
      "83m 58s (- 4m 13s) (6300 95%) 1.2508\n",
      "85m 18s (- 2m 53s) (6400 96%) 1.2490\n",
      "86m 38s (- 1m 33s) (6500 98%) 1.2677\n",
      "87m 58s (- 0m 13s) (6600 99%) 1.2738\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_size = 256\n",
    "\n",
    "\n",
    "# encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "# attn_decoder = PreBatchAttnDecoderRNN(loaded_zh_embeddings, emb_size,hidden_size, len(zh_ordered_words)).to(device)\n",
    "\n",
    "AttnTrainIters(train_zh_loader, val_zh_loader, encoder, attn_decoder, 1,\n",
    "               None, print_every=100, learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 21s (- 177m 50s) (100 0%) 1.2942\n",
      "2m 41s (- 175m 37s) (200 1%) 1.3167\n",
      "4m 1s (- 173m 45s) (300 2%) 1.2504\n",
      "5m 21s (- 172m 6s) (400 3%) 1.2793\n",
      "6m 41s (- 170m 13s) (500 3%) 1.2506\n",
      "8m 0s (- 168m 39s) (600 4%) 1.2727\n",
      "9m 20s (- 167m 15s) (700 5%) 1.2799\n",
      "10m 39s (- 165m 46s) (800 6%) 1.2354\n",
      "11m 59s (- 164m 19s) (900 6%) 1.2389\n",
      "13m 19s (- 162m 58s) (1000 7%) 1.2446\n",
      "14m 38s (- 161m 34s) (1100 8%) 1.2366\n",
      "15m 58s (- 160m 8s) (1200 9%) 1.2649\n",
      "17m 17s (- 158m 44s) (1300 9%) 1.2776\n",
      "18m 37s (- 157m 28s) (1400 10%) 1.2547\n",
      "19m 57s (- 156m 7s) (1500 11%) 1.2226\n",
      "21m 17s (- 154m 47s) (1600 12%) 1.2337\n",
      "22m 36s (- 153m 22s) (1700 12%) 1.2139\n",
      "23m 55s (- 151m 57s) (1800 13%) 1.2386\n",
      "25m 13s (- 150m 30s) (1900 14%) 1.2052\n",
      "26m 32s (- 149m 7s) (2000 15%) 1.2269\n",
      "27m 51s (- 147m 44s) (2100 15%) 1.2692\n",
      "29m 11s (- 146m 23s) (2200 16%) 1.2328\n",
      "30m 31s (- 145m 4s) (2300 17%) 1.2231\n",
      "31m 50s (- 143m 42s) (2400 18%) 1.2024\n",
      "33m 9s (- 142m 22s) (2500 18%) 1.2112\n",
      "34m 29s (- 141m 4s) (2600 19%) 1.2417\n",
      "35m 49s (- 139m 46s) (2700 20%) 1.2657\n",
      "37m 8s (- 138m 25s) (2800 21%) 1.2039\n",
      "38m 29s (- 137m 8s) (2900 21%) 1.2510\n",
      "39m 49s (- 135m 50s) (3000 22%) 1.2678\n",
      "41m 8s (- 134m 30s) (3100 23%) 1.2192\n",
      "42m 27s (- 133m 8s) (3200 24%) 1.1820\n",
      "43m 47s (- 131m 50s) (3300 24%) 1.2193\n",
      "45m 7s (- 130m 30s) (3400 25%) 1.2157\n",
      "46m 26s (- 129m 10s) (3500 26%) 1.2354\n",
      "47m 46s (- 127m 50s) (3600 27%) 1.1848\n",
      "49m 6s (- 126m 33s) (3700 27%) 1.2145\n",
      "50m 26s (- 125m 14s) (3800 28%) 1.2000\n",
      "51m 47s (- 123m 56s) (3900 29%) 1.2105\n",
      "53m 7s (- 122m 37s) (4000 30%) 1.2032\n",
      "54m 26s (- 121m 18s) (4100 30%) 1.2112\n",
      "55m 46s (- 119m 58s) (4200 31%) 1.1793\n",
      "57m 7s (- 118m 41s) (4300 32%) 1.2263\n",
      "58m 27s (- 117m 22s) (4400 33%) 1.2087\n",
      "59m 47s (- 116m 3s) (4500 34%) 1.2354\n",
      "61m 8s (- 114m 45s) (4600 34%) 1.1976\n",
      "62m 28s (- 113m 25s) (4700 35%) 1.1884\n",
      "63m 48s (- 112m 6s) (4800 36%) 1.1766\n",
      "65m 8s (- 110m 47s) (4900 37%) 1.1922\n",
      "66m 28s (- 109m 28s) (5000 37%) 1.2249\n",
      "67m 48s (- 108m 8s) (5100 38%) 1.1669\n",
      "69m 8s (- 106m 50s) (5200 39%) 1.2131\n",
      "70m 29s (- 105m 30s) (5300 40%) 1.1958\n",
      "71m 49s (- 104m 12s) (5400 40%) 1.1872\n",
      "73m 9s (- 102m 53s) (5500 41%) 1.2239\n",
      "74m 30s (- 101m 34s) (5600 42%) 1.2488\n",
      "75m 50s (- 100m 14s) (5700 43%) 1.1761\n",
      "77m 11s (- 98m 56s) (5800 43%) 1.1933\n",
      "78m 31s (- 97m 36s) (5900 44%) 1.1909\n",
      "79m 51s (- 96m 17s) (6000 45%) 1.1616\n",
      "81m 12s (- 94m 57s) (6100 46%) 1.2123\n",
      "82m 32s (- 93m 38s) (6200 46%) 1.1934\n",
      "83m 52s (- 92m 18s) (6300 47%) 1.1891\n",
      "85m 12s (- 90m 59s) (6400 48%) 1.1869\n",
      "86m 32s (- 89m 39s) (6500 49%) 1.1557\n",
      "87m 52s (- 88m 19s) (6600 49%) 1.1987\n",
      "89m 27s (- 86m 47s) (6717 50%) 1.3978\n",
      "90m 47s (- 85m 27s) (6817 51%) 1.1433\n",
      "92m 7s (- 84m 7s) (6917 52%) 1.1515\n",
      "93m 26s (- 82m 47s) (7017 53%) 1.1276\n",
      "94m 46s (- 81m 27s) (7117 53%) 1.1323\n",
      "96m 7s (- 80m 8s) (7217 54%) 1.1903\n",
      "97m 27s (- 78m 48s) (7317 55%) 1.1443\n",
      "98m 47s (- 77m 28s) (7417 56%) 1.1739\n",
      "100m 7s (- 76m 9s) (7517 56%) 1.1369\n",
      "101m 27s (- 74m 49s) (7617 57%) 1.1292\n",
      "102m 47s (- 73m 29s) (7717 58%) 1.1575\n",
      "104m 7s (- 72m 9s) (7817 59%) 1.1437\n",
      "105m 28s (- 70m 50s) (7917 59%) 1.1857\n",
      "106m 48s (- 69m 30s) (8017 60%) 1.1592\n",
      "108m 9s (- 68m 10s) (8117 61%) 1.1717\n",
      "109m 29s (- 66m 51s) (8217 62%) 1.1486\n",
      "110m 49s (- 65m 31s) (8317 62%) 1.1637\n",
      "112m 10s (- 64m 11s) (8417 63%) 1.2004\n",
      "113m 30s (- 62m 51s) (8517 64%) 1.1115\n",
      "114m 50s (- 61m 31s) (8617 65%) 1.1322\n",
      "116m 10s (- 60m 11s) (8717 65%) 1.1378\n",
      "117m 30s (- 58m 51s) (8817 66%) 1.1470\n",
      "118m 50s (- 57m 32s) (8917 67%) 1.1663\n",
      "120m 10s (- 56m 12s) (9017 68%) 1.1406\n",
      "121m 30s (- 54m 52s) (9117 68%) 1.1371\n",
      "122m 51s (- 53m 32s) (9217 69%) 1.1674\n",
      "124m 11s (- 52m 12s) (9317 70%) 1.1224\n",
      "125m 31s (- 50m 52s) (9417 71%) 1.1391\n",
      "126m 51s (- 49m 32s) (9517 71%) 1.1436\n",
      "128m 11s (- 48m 12s) (9617 72%) 1.1346\n",
      "129m 31s (- 46m 52s) (9717 73%) 1.1664\n",
      "130m 51s (- 45m 32s) (9817 74%) 1.1514\n",
      "132m 11s (- 44m 12s) (9917 74%) 1.1458\n",
      "133m 31s (- 42m 52s) (10017 75%) 1.1462\n",
      "134m 51s (- 41m 33s) (10117 76%) 1.1354\n",
      "136m 12s (- 40m 13s) (10217 77%) 1.1436\n",
      "137m 32s (- 38m 53s) (10317 77%) 1.1457\n",
      "138m 52s (- 37m 33s) (10417 78%) 1.2127\n",
      "140m 13s (- 36m 13s) (10517 79%) 1.1605\n",
      "141m 33s (- 34m 53s) (10617 80%) 1.1558\n",
      "142m 54s (- 33m 33s) (10717 80%) 1.1722\n",
      "144m 14s (- 32m 13s) (10817 81%) 1.1582\n",
      "145m 34s (- 30m 53s) (10917 82%) 1.1350\n",
      "146m 54s (- 29m 33s) (11017 83%) 1.1366\n",
      "148m 15s (- 28m 13s) (11117 84%) 1.1766\n",
      "149m 35s (- 26m 53s) (11217 84%) 1.1281\n",
      "150m 54s (- 25m 33s) (11317 85%) 1.0721\n",
      "152m 14s (- 24m 13s) (11417 86%) 1.1316\n",
      "153m 35s (- 22m 53s) (11517 87%) 1.1815\n",
      "154m 55s (- 21m 33s) (11617 87%) 1.1351\n",
      "156m 15s (- 20m 13s) (11717 88%) 1.1459\n",
      "157m 35s (- 18m 53s) (11817 89%) 1.1062\n",
      "158m 55s (- 17m 33s) (11917 90%) 1.1528\n",
      "160m 15s (- 16m 13s) (12017 90%) 1.1762\n",
      "161m 36s (- 14m 53s) (12117 91%) 1.1367\n",
      "162m 56s (- 13m 33s) (12217 92%) 1.1589\n",
      "164m 17s (- 12m 13s) (12317 93%) 1.1479\n",
      "165m 37s (- 10m 53s) (12417 93%) 1.1178\n",
      "166m 58s (- 9m 33s) (12517 94%) 1.1701\n",
      "168m 17s (- 8m 13s) (12617 95%) 1.1509\n",
      "169m 37s (- 6m 53s) (12717 96%) 1.1309\n",
      "170m 57s (- 5m 33s) (12817 96%) 1.1377\n",
      "172m 16s (- 4m 13s) (12917 97%) 1.1290\n",
      "173m 36s (- 2m 53s) (13017 98%) 1.1600\n",
      "174m 56s (- 1m 33s) (13117 99%) 1.1244\n",
      "176m 16s (- 0m 13s) (13217 99%) 1.1367\n"
     ]
    }
   ],
   "source": [
    "plot_losses = AttnTrainIters(train_zh_loader, val_zh_loader, encoder, attn_decoder, 2,\n",
    "               None, print_every=100, learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_backup = encoder\n",
    "decoder_backup = attn_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_backup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-be7f79364f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_backup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_backup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_backup' is not defined"
     ]
    }
   ],
   "source": [
    "encoder_backup, decoder_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 20s (- 265m 30s) (100 0%) 2.6145\n",
      "2m 39s (- 261m 42s) (200 1%) 1.6224\n",
      "3m 59s (- 259m 50s) (300 1%) 1.6505\n",
      "5m 18s (- 258m 5s) (400 2%) 1.5879\n",
      "6m 37s (- 256m 25s) (500 2%) 1.5498\n",
      "7m 56s (- 255m 2s) (600 3%) 1.5647\n",
      "9m 16s (- 253m 45s) (700 3%) 1.5371\n",
      "10m 35s (- 252m 18s) (800 4%) 1.5224\n",
      "11m 55s (- 251m 2s) (900 4%) 1.5255\n",
      "13m 14s (- 249m 44s) (1000 5%) 1.4968\n",
      "14m 34s (- 248m 28s) (1100 5%) 1.4864\n",
      "15m 54s (- 247m 10s) (1200 6%) 1.4749\n",
      "17m 13s (- 245m 51s) (1300 6%) 1.4653\n",
      "18m 33s (- 244m 34s) (1400 7%) 1.4737\n",
      "19m 53s (- 243m 16s) (1500 7%) 1.4448\n",
      "21m 12s (- 241m 55s) (1600 8%) 1.4515\n",
      "22m 31s (- 240m 33s) (1700 8%) 1.4294\n",
      "23m 51s (- 239m 17s) (1800 9%) 1.4517\n",
      "25m 11s (- 237m 59s) (1900 9%) 1.4343\n",
      "26m 30s (- 236m 38s) (2000 10%) 1.4094\n",
      "27m 50s (- 235m 22s) (2100 10%) 1.4206\n",
      "29m 10s (- 234m 2s) (2200 11%) 1.3789\n",
      "30m 29s (- 232m 40s) (2300 11%) 1.3468\n",
      "31m 48s (- 231m 19s) (2400 12%) 1.3678\n",
      "33m 8s (- 229m 57s) (2500 12%) 1.3789\n",
      "34m 28s (- 228m 41s) (2600 13%) 1.4265\n",
      "35m 47s (- 227m 20s) (2700 13%) 1.3813\n",
      "37m 6s (- 225m 59s) (2800 14%) 1.3414\n",
      "38m 25s (- 224m 38s) (2900 14%) 1.3529\n",
      "39m 45s (- 223m 17s) (3000 15%) 1.3247\n",
      "41m 3s (- 221m 54s) (3100 15%) 1.3057\n",
      "42m 23s (- 220m 34s) (3200 16%) 1.3352\n",
      "43m 42s (- 219m 14s) (3300 16%) 1.3393\n",
      "45m 2s (- 217m 54s) (3400 17%) 1.3440\n",
      "46m 21s (- 216m 34s) (3500 17%) 1.3173\n",
      "47m 40s (- 215m 14s) (3600 18%) 1.3247\n",
      "49m 0s (- 213m 55s) (3700 18%) 1.2784\n",
      "50m 20s (- 212m 36s) (3800 19%) 1.3043\n",
      "51m 39s (- 211m 16s) (3900 19%) 1.3227\n",
      "52m 59s (- 210m 0s) (4000 20%) 1.3440\n",
      "54m 19s (- 208m 40s) (4100 20%) 1.2827\n",
      "55m 38s (- 207m 20s) (4200 21%) 1.3382\n",
      "56m 57s (- 205m 59s) (4300 21%) 1.2751\n",
      "58m 17s (- 204m 41s) (4400 22%) 1.3156\n",
      "59m 37s (- 203m 22s) (4500 22%) 1.2881\n",
      "60m 56s (- 202m 3s) (4600 23%) 1.3120\n",
      "62m 15s (- 200m 41s) (4700 23%) 1.2601\n",
      "63m 34s (- 199m 22s) (4800 24%) 1.3014\n",
      "64m 55s (- 198m 4s) (4900 24%) 1.3253\n",
      "66m 14s (- 196m 45s) (5000 25%) 1.2732\n",
      "67m 34s (- 195m 26s) (5100 25%) 1.2837\n",
      "68m 53s (- 194m 7s) (5200 26%) 1.3096\n",
      "70m 13s (- 192m 48s) (5300 26%) 1.3202\n",
      "71m 33s (- 191m 28s) (5400 27%) 1.2528\n",
      "72m 53s (- 190m 11s) (5500 27%) 1.2621\n",
      "74m 13s (- 188m 52s) (5600 28%) 1.2642\n",
      "75m 33s (- 187m 34s) (5700 28%) 1.2480\n",
      "76m 53s (- 186m 15s) (5800 29%) 1.2419\n",
      "78m 13s (- 184m 57s) (5900 29%) 1.2549\n",
      "79m 33s (- 183m 38s) (6000 30%) 1.2803\n",
      "80m 52s (- 182m 18s) (6100 30%) 1.2581\n",
      "82m 12s (- 180m 59s) (6200 31%) 1.2560\n",
      "83m 31s (- 179m 39s) (6300 31%) 1.2453\n",
      "84m 51s (- 178m 20s) (6400 32%) 1.3074\n",
      "86m 10s (- 177m 1s) (6500 32%) 1.2471\n",
      "87m 30s (- 175m 42s) (6600 33%) 1.2999\n",
      "89m 4s (- 174m 9s) (6717 33%) 1.2407\n",
      "90m 23s (- 172m 48s) (6817 34%) 1.1760\n",
      "91m 42s (- 171m 29s) (6917 34%) 1.2509\n",
      "93m 1s (- 170m 8s) (7017 35%) 1.2152\n",
      "94m 21s (- 168m 49s) (7117 35%) 1.2099\n",
      "95m 40s (- 167m 29s) (7217 36%) 1.2298\n",
      "97m 0s (- 166m 10s) (7317 36%) 1.1994\n",
      "98m 19s (- 164m 50s) (7417 37%) 1.2033\n",
      "99m 39s (- 163m 31s) (7517 37%) 1.2438\n",
      "100m 58s (- 162m 11s) (7617 38%) 1.2455\n",
      "102m 18s (- 160m 51s) (7717 38%) 1.1859\n",
      "103m 38s (- 159m 32s) (7817 39%) 1.2593\n",
      "104m 57s (- 158m 12s) (7917 39%) 1.2050\n",
      "106m 17s (- 156m 53s) (8017 40%) 1.2152\n",
      "107m 36s (- 155m 33s) (8117 40%) 1.2182\n",
      "108m 55s (- 154m 13s) (8217 41%) 1.2244\n",
      "110m 15s (- 152m 53s) (8317 41%) 1.1974\n",
      "111m 34s (- 151m 34s) (8417 42%) 1.2524\n",
      "112m 54s (- 150m 15s) (8517 42%) 1.2170\n",
      "114m 13s (- 148m 55s) (8617 43%) 1.2082\n",
      "115m 33s (- 147m 35s) (8717 43%) 1.1786\n",
      "116m 52s (- 146m 15s) (8817 44%) 1.1943\n",
      "118m 11s (- 144m 55s) (8917 44%) 1.1778\n",
      "119m 31s (- 143m 36s) (9017 45%) 1.2040\n",
      "120m 51s (- 142m 17s) (9117 45%) 1.1766\n",
      "122m 11s (- 140m 58s) (9217 46%) 1.2138\n",
      "123m 31s (- 139m 39s) (9317 46%) 1.1943\n",
      "124m 51s (- 138m 20s) (9417 47%) 1.1978\n",
      "126m 11s (- 137m 1s) (9517 47%) 1.1819\n",
      "127m 31s (- 135m 42s) (9617 48%) 1.1919\n",
      "128m 51s (- 134m 22s) (9717 48%) 1.1734\n",
      "130m 11s (- 133m 3s) (9817 49%) 1.2008\n",
      "131m 31s (- 131m 44s) (9917 49%) 1.1964\n",
      "132m 50s (- 130m 25s) (10017 50%) 1.1696\n",
      "134m 10s (- 129m 5s) (10117 50%) 1.1827\n",
      "135m 30s (- 127m 46s) (10217 51%) 1.1925\n",
      "136m 50s (- 126m 26s) (10317 51%) 1.1771\n",
      "138m 10s (- 125m 7s) (10417 52%) 1.1817\n",
      "139m 29s (- 123m 48s) (10517 52%) 1.1873\n",
      "140m 50s (- 122m 29s) (10617 53%) 1.2483\n",
      "142m 10s (- 121m 10s) (10717 53%) 1.1944\n",
      "143m 30s (- 119m 51s) (10817 54%) 1.2017\n",
      "144m 50s (- 118m 31s) (10917 54%) 1.1534\n",
      "146m 10s (- 117m 12s) (11017 55%) 1.1949\n",
      "147m 30s (- 115m 53s) (11117 56%) 1.1524\n",
      "148m 50s (- 114m 34s) (11217 56%) 1.2217\n",
      "150m 11s (- 113m 15s) (11317 57%) 1.2156\n",
      "151m 31s (- 111m 55s) (11417 57%) 1.1594\n",
      "152m 51s (- 110m 36s) (11517 58%) 1.1661\n",
      "154m 10s (- 109m 16s) (11617 58%) 1.1616\n",
      "155m 30s (- 107m 57s) (11717 59%) 1.2245\n",
      "156m 49s (- 106m 37s) (11817 59%) 1.1576\n",
      "158m 9s (- 105m 17s) (11917 60%) 1.2044\n",
      "159m 28s (- 103m 57s) (12017 60%) 1.1621\n",
      "160m 48s (- 102m 38s) (12117 61%) 1.1694\n",
      "162m 7s (- 101m 18s) (12217 61%) 1.1756\n",
      "163m 28s (- 99m 59s) (12317 62%) 1.1702\n",
      "164m 48s (- 98m 39s) (12417 62%) 1.1781\n",
      "166m 7s (- 97m 20s) (12517 63%) 1.1442\n",
      "167m 28s (- 96m 1s) (12617 63%) 1.2172\n",
      "168m 48s (- 94m 42s) (12717 64%) 1.2171\n",
      "170m 8s (- 93m 22s) (12817 64%) 1.1529\n",
      "171m 28s (- 92m 2s) (12917 65%) 1.1787\n",
      "172m 48s (- 90m 43s) (13017 65%) 1.1722\n",
      "174m 8s (- 89m 24s) (13117 66%) 1.1916\n",
      "175m 28s (- 88m 4s) (13217 66%) 1.1917\n",
      "177m 2s (- 86m 31s) (13334 67%) 1.1724\n",
      "178m 22s (- 85m 12s) (13434 67%) 1.1110\n",
      "179m 42s (- 83m 52s) (13534 68%) 1.1634\n",
      "181m 2s (- 82m 33s) (13634 68%) 1.1368\n",
      "182m 22s (- 81m 13s) (13734 69%) 1.1578\n",
      "183m 41s (- 79m 53s) (13834 69%) 1.1098\n",
      "185m 1s (- 78m 34s) (13934 70%) 1.1467\n",
      "186m 21s (- 77m 14s) (14034 70%) 1.1325\n",
      "187m 41s (- 75m 55s) (14134 71%) 1.1763\n",
      "189m 1s (- 74m 35s) (14234 71%) 1.1681\n",
      "190m 20s (- 73m 15s) (14334 72%) 1.1443\n",
      "191m 40s (- 71m 56s) (14434 72%) 1.1204\n",
      "193m 0s (- 70m 36s) (14534 73%) 1.1446\n",
      "194m 21s (- 69m 17s) (14634 73%) 1.1105\n",
      "195m 40s (- 67m 57s) (14734 74%) 1.1707\n",
      "197m 0s (- 66m 37s) (14834 74%) 1.1611\n",
      "198m 20s (- 65m 18s) (14934 75%) 1.1613\n",
      "199m 39s (- 63m 58s) (15034 75%) 1.1531\n",
      "200m 59s (- 62m 38s) (15134 76%) 1.1397\n",
      "202m 18s (- 61m 18s) (15234 76%) 1.1194\n",
      "203m 37s (- 59m 59s) (15334 77%) 1.1187\n",
      "204m 56s (- 58m 39s) (15434 77%) 1.1111\n",
      "206m 16s (- 57m 19s) (15534 78%) 1.1026\n",
      "207m 35s (- 55m 59s) (15634 78%) 1.1047\n",
      "208m 54s (- 54m 39s) (15734 79%) 1.1384\n",
      "210m 13s (- 53m 19s) (15834 79%) 1.0856\n",
      "211m 33s (- 52m 0s) (15934 80%) 1.1933\n",
      "212m 52s (- 50m 40s) (16034 80%) 1.1724\n",
      "214m 12s (- 49m 20s) (16134 81%) 1.1413\n",
      "215m 31s (- 48m 1s) (16234 81%) 1.1337\n",
      "216m 51s (- 46m 41s) (16334 82%) 1.1224\n",
      "218m 10s (- 45m 21s) (16434 82%) 1.1417\n",
      "219m 29s (- 44m 2s) (16534 83%) 1.1049\n",
      "220m 48s (- 42m 42s) (16634 83%) 1.0995\n",
      "222m 7s (- 41m 22s) (16734 84%) 1.1259\n",
      "223m 27s (- 40m 2s) (16834 84%) 1.1222\n",
      "224m 47s (- 38m 43s) (16934 85%) 1.1617\n",
      "226m 6s (- 37m 23s) (17034 85%) 1.1315\n",
      "227m 25s (- 36m 3s) (17134 86%) 1.1439\n",
      "228m 45s (- 34m 44s) (17234 86%) 1.1227\n",
      "230m 4s (- 33m 24s) (17334 87%) 1.1145\n",
      "231m 23s (- 32m 4s) (17434 87%) 1.1405\n",
      "232m 42s (- 30m 45s) (17534 88%) 1.1629\n",
      "234m 2s (- 29m 25s) (17634 88%) 1.1228\n",
      "235m 21s (- 28m 5s) (17734 89%) 1.1230\n",
      "236m 41s (- 26m 46s) (17834 89%) 1.1401\n",
      "238m 0s (- 25m 26s) (17934 90%) 1.1208\n",
      "239m 19s (- 24m 6s) (18034 90%) 1.1244\n",
      "240m 39s (- 22m 47s) (18134 91%) 1.1460\n",
      "241m 58s (- 21m 27s) (18234 91%) 1.1270\n",
      "243m 17s (- 20m 7s) (18334 92%) 1.0860\n",
      "244m 36s (- 18m 48s) (18434 92%) 1.1364\n",
      "245m 55s (- 17m 28s) (18534 93%) 1.1018\n",
      "247m 15s (- 16m 8s) (18634 93%) 1.1162\n",
      "248m 34s (- 14m 49s) (18734 94%) 1.1901\n",
      "249m 54s (- 13m 29s) (18834 94%) 1.1229\n",
      "251m 14s (- 12m 10s) (18934 95%) 1.1130\n",
      "252m 33s (- 10m 50s) (19034 95%) 1.1324\n",
      "253m 52s (- 9m 30s) (19134 96%) 1.1350\n",
      "255m 13s (- 8m 11s) (19234 96%) 1.1357\n",
      "256m 33s (- 6m 51s) (19334 97%) 1.1843\n",
      "257m 53s (- 5m 32s) (19434 97%) 1.1224\n",
      "259m 13s (- 4m 12s) (19534 98%) 1.0966\n",
      "260m 33s (- 2m 52s) (19634 98%) 1.1181\n",
      "261m 53s (- 1m 33s) (19734 99%) 1.1071\n",
      "263m 13s (- 0m 13s) (19834 99%) 1.1438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_size = 256\n",
    "\n",
    "# encoder = PreBatchEncoderRNN(loaded_zh_embeddings, emb_size, hidden_size).to(device)\n",
    "# attn_decoder = PreBatchAttnDecoderRNN(loaded_en_embeddings, emb_size,hidden_size, len(en_ordered_words)).to(device)\n",
    "\n",
    "total_loss_list_en, plot_losses_en = AttnTrainIters(train_zh_loader, val_zh_loader, encoder, attn_decoder, 3,\n",
    "               None, print_every=100, learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(total_loss_list_en, open('total_loss_list_en.p', 'wb'))\n",
    "pkl.dump(plot_losses_en, open('plot_losses_en.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 20s (- 87m 52s) (100 1%) 1.0752\n",
      "2m 40s (- 85m 55s) (200 3%) 1.0620\n",
      "4m 0s (- 84m 17s) (300 4%) 1.0473\n",
      "5m 19s (- 82m 41s) (400 6%) 1.0268\n",
      "6m 39s (- 81m 21s) (500 7%) 1.0890\n",
      "7m 58s (- 79m 59s) (600 9%) 1.0692\n",
      "9m 18s (- 78m 38s) (700 10%) 1.0784\n"
     ]
    }
   ],
   "source": [
    "total_loss_list_en3, plot_losses_en3 = AttnTrainIters(train_zh_loader, val_zh_loader, encoder, attn_decoder, 1,\n",
    "               None, print_every=100, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plot_losses_en2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss_append = plot_losses_en + plot_losses_en2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "ax.yaxis.set_major_locator(loc)\n",
    "plt.plot(total_loss_list_en)\n",
    "\n",
    "plt.title('Total Training loss with respect to time')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.savefig('total_zh_attn_training_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "ax.yaxis.set_major_locator(loc)\n",
    "plt.plot(plot_loss_append)\n",
    "\n",
    "plt.title('Training loss curve on ZH-EN for decoder with attnetion')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('zh_attn_training_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plot_loss_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(plot_loss_append, open('plot_losses_append_zh_attn.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_backup = attn_decoder\n",
    "encoder_backup = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1396\n",
      "100/1396\n",
      "200/1396\n",
      "300/1396\n",
      "400/1396\n",
      "500/1396\n",
      "600/1396\n",
      "700/1396\n",
      "800/1396\n",
      "900/1396\n",
      "1000/1396\n",
      "1100/1396\n",
      "1200/1396\n",
      "1300/1396\n"
     ]
    }
   ],
   "source": [
    "decoded_test, decoder_attentions = greedy_attn_evaluate(test_zh_loader, encoder, attn_decoder, en_id2words)\n",
    "decoded_test_clean = post_process(decoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(decoded_test_clean, open('attn_decoded_test_clean5.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score for test dataset: 13.244067757436477\n",
      "bleu score for test dataset [raw]: 3.1149446308128703\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so', 'there', 's', 'this', '.', 'this', '.', '.', '<EOS>']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(decoded_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time = timer()\n",
    "i = 0\n",
    "for batch in train_zh_loader:\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beam_evaluate(val_loader, encoder, decoder, beam_width, k):\n",
    "    '''\n",
    "    beam_width: number of best nodes kept at each iterations\n",
    "    k: number of sentences we want to keep\n",
    "    Returns the translated batch\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    decoded_batch = []\n",
    "    #decoder_attentions = torch.zeros(max_length, batch_size, max_input_length)#in length, each position has attention\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for i, (input_list, input_length, output_list, output_length) in enumerate(val_loader):\n",
    "            if i %100 == 0:\n",
    "                print(\"%d/%d\"%(i,len(val_loader)))\n",
    "                    \n",
    "            #    break\n",
    "            #batch_size, max_len = output_list.size()\n",
    "#             print(input_list.size())\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden(1)\n",
    "            encoder_outputs, encoder_hidden = encoder(input_list, input_length, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.tensor(np.array([[SOS_TOKEN]]), device=device) #SOS 1 sentence a time\n",
    "            decoder_hidden = encoder_hidden[:decoder.n_layers] # decoder starts from the last encoding sentence\n",
    "            # output of this function\n",
    "            \n",
    "            decoded_words = []\n",
    "            #decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
    "            \n",
    "            start_node = SearchNode(decoder_input, decoder_hidden, prev = None, curr_score = 0, length = 1)\n",
    "            nodes = PriorityQueue()\n",
    "            nodes.put(( -(start_node.score), start_node))\n",
    "            end_nodes = []\n",
    "            \n",
    "\n",
    "            while(len(end_nodes) < k):\n",
    "                curr_score, curr_node = nodes.get()\n",
    "                if (curr_node.word_idx == EOS_TOKEN) and (curr_node.prev != None):\n",
    "                    end_nodes.append((-(curr_node.score),curr_node))\n",
    "                    if len(end_nodes) >=k:\n",
    "                        break;\n",
    "                    else: \n",
    "                        continue;\n",
    "\n",
    "                if nodes.qsize() >= MAX_LENGTH:#if too long will force to stop\n",
    "                    #Create an EOS dummy node to trace back the entire sentence\n",
    "                    EOS_node = SearchNode(torch.tensor([[EOS_TOKEN]], device = device), curr_node.hidden, \n",
    "                                          curr_node, curr_node.score, (curr_node.length)+1)\n",
    "                    end_nodes.append((-(EOS_node.score), EOS_node))\n",
    "                    if len(end_nodes) >= k:\n",
    "                        break;\n",
    "                    else:\n",
    "                        continue;\n",
    "\n",
    "                decoder_input = curr_node.word_idx\n",
    "                decoder_hidden = curr_node.hidden\n",
    "\n",
    "                # for each time step, the decoder network takes two inputs: previous outputs \n",
    "                #and the previous hidden states\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "\n",
    "                scores, indexes = torch.topk(decoder_output, beam_width)\n",
    "                candidate_nodes = []\n",
    "                for i in range(beam_width):\n",
    "                    candidate_idx = indexes[0][i].view(1, -1)\n",
    "                    candidate_score = scores[0][i].item()\n",
    "\n",
    "                    candidate_node = SearchNode(candidate_idx, decoder_hidden, \n",
    "                                                   curr_node, candidate_score, curr_node.length + 1)\n",
    "                    candidate_nodes.append((-(candidate_node.score), candidate_node))\n",
    "\n",
    "                for j in range(beam_width):\n",
    "                    to_push_score, to_push_node = candidate_nodes[j]\n",
    "                    #print(to_push_score)\n",
    "                    nodes.put((-(to_push_score), to_push_node))\n",
    "                #End of the while loop\n",
    "\n",
    "            sentences = translate_end_nodes(end_nodes)\n",
    "            decoded_batch.append(sentences)\n",
    "            #End of the batch loop\n",
    "        \n",
    "    return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SearchNode(object):\n",
    "    def __init__(self, word_idx, hidden, prev, curr_score, length):\n",
    "        self.hidden = hidden\n",
    "        self.word_idx = word_idx\n",
    "        self.prev = prev\n",
    "        \n",
    "        if self.prev == None:\n",
    "            self.score = curr_score\n",
    "        else:\n",
    "            self.score = self.prev.score + curr_score\n",
    "        self.length = length\n",
    "\n",
    "#Translate the sentences.\n",
    "def translate_end_nodes(end_nodes):\n",
    "    sentences = []\n",
    "    #end_nodes = sorted(end_nodes, key = operator.itemgetter(0),reverse = True)\n",
    "    for _, end_node in end_nodes:\n",
    "        sentence = []\n",
    "        while end_node.prev != None:\n",
    "            sentence.append(en_id2words[end_node.word_idx.item()])\n",
    "            end_node = end_node.prev\n",
    "        sentence = sentence[::-1]#Reverse the sentence to get the sentence\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1257\n",
      "100/1257\n",
      "200/1257\n",
      "300/1257\n",
      "400/1257\n",
      "500/1257\n",
      "600/1257\n",
      "700/1257\n",
      "800/1257\n",
      "900/1257\n",
      "1000/1257\n",
      "1100/1257\n",
      "1200/1257\n"
     ]
    }
   ],
   "source": [
    "decoded_val = beam_evaluate(val_zh_loader, encoder, attn_decoder, 5,1)\n",
    "decoded_clean = post_process(decoded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我们 欣慰 地 发现 国内 的 年轻 年轻人 正在 权威 地 解释 议事 阻挠 是 什么 为什么 什么 上院 议员 们 要 牺牲 睡眠 来 捍卫 原则',\n",
       " 'and it was with great delight that we found young people up and down the country explaining with authority what filibustering was and why the lords might defy their bedtime on a point of principle .']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_zh_pairs[763]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
